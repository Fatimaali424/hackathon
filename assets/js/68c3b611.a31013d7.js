"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[629],{4660(e,n,t){t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>m});const r=JSON.parse('{"id":"module-3/lab-9-edge-deployment","title":"Lab 9: Edge Deployment and Optimization","description":"Overview","source":"@site/docs/module-3/lab-9-edge-deployment.md","sourceDirName":"module-3","slug":"/module-3/lab-9-edge-deployment","permalink":"/hackathon/docs/module-3/lab-9-edge-deployment","draft":false,"unlisted":false,"editUrl":"https://github.com/Fatimaali424/hackathon/edit/main/website/docs/module-3/lab-9-edge-deployment.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Lab 8: Motion Planning and Control Implementation","permalink":"/hackathon/docs/module-3/lab-8-motion-control"},"next":{"title":"Module 3 Assignment: AI-Robot Brain Implementation","permalink":"/hackathon/docs/module-3/assignment"}}');var i=t(4848),o=t(8453);const s={sidebar_position:7},l="Lab 9: Edge Deployment and Optimization",a={},m=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Hardware and Software Requirements",id:"hardware-and-software-requirements",level:2},{value:"Required Hardware",id:"required-hardware",level:3},{value:"Required Software",id:"required-software",level:3},{value:"Lab Setup",id:"lab-setup",level:2},{value:"Environment Preparation",id:"environment-preparation",level:3},{value:"Development Environment Setup",id:"development-environment-setup",level:3},{value:"Implementation Steps",id:"implementation-steps",level:2},{value:"Step 1: Containerized Application Structure",id:"step-1-containerized-application-structure",level:3},{value:"Step 2: TensorRT Model Optimization",id:"step-2-tensorrt-model-optimization",level:3},{value:"Step 3: Resource Management and Optimization",id:"step-3-resource-management-and-optimization",level:3},{value:"Step 4: Real-Time Performance Optimization",id:"step-4-real-time-performance-optimization",level:3},{value:"Step 5: Main Application with Optimization",id:"step-5-main-application-with-optimization",level:3},{value:"Testing and Validation",id:"testing-and-validation",level:2},{value:"Performance Testing Script",id:"performance-testing-script",level:3},{value:"Power and Thermal Management",id:"power-and-thermal-management",level:2},{value:"Deployment Scripts",id:"deployment-scripts",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:3},{value:"Lab Deliverables",id:"lab-deliverables",level:2},{value:"Assessment Criteria",id:"assessment-criteria",level:2},{value:"Extensions (Optional)",id:"extensions-optional",level:2},{value:"Summary",id:"summary",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"lab-9-edge-deployment-and-optimization",children:"Lab 9: Edge Deployment and Optimization"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"This lab focuses on deploying and optimizing Isaac-based robotic applications on edge computing platforms, specifically NVIDIA Jetson devices. You will learn to containerize applications, optimize for resource constraints, implement efficient memory management, and validate performance in resource-constrained environments."}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"After completing this lab, you will be able to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Containerize Isaac applications using Docker for Jetson platforms"}),"\n",(0,i.jsx)(n.li,{children:"Optimize neural network models for edge deployment using TensorRT"}),"\n",(0,i.jsx)(n.li,{children:"Implement efficient resource management for real-time applications"}),"\n",(0,i.jsx)(n.li,{children:"Profile and optimize application performance on edge devices"}),"\n",(0,i.jsx)(n.li,{children:"Deploy applications with appropriate power and thermal management"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Completion of Module 1 (ROS 2 fundamentals)"}),"\n",(0,i.jsx)(n.li,{children:"Completion of Module 2 (Simulation concepts)"}),"\n",(0,i.jsx)(n.li,{children:"Completion of Module 3 (Isaac perception and planning)"}),"\n",(0,i.jsx)(n.li,{children:"Basic understanding of Docker and containerization"}),"\n",(0,i.jsx)(n.li,{children:"Access to a Jetson platform (Orin AGX/NX/Nano) or cross-compilation environment"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"hardware-and-software-requirements",children:"Hardware and Software Requirements"}),"\n",(0,i.jsx)(n.h3,{id:"required-hardware",children:"Required Hardware"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"NVIDIA Jetson Orin AGX/NX/Nano development kit"}),"\n",(0,i.jsx)(n.li,{children:"Power supply capable of delivering required power (varies by Jetson model)"}),"\n",(0,i.jsx)(n.li,{children:"MicroSD card (64GB+ recommended) or eMMC storage"}),"\n",(0,i.jsx)(n.li,{children:"USB-C cable for power and data (if needed)"}),"\n",(0,i.jsx)(n.li,{children:"Cooling solution (active cooling recommended for Orin AGX)"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"required-software",children:"Required Software"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"JetPack 5.1+ installed on Jetson device"}),"\n",(0,i.jsx)(n.li,{children:"Docker and nvidia-docker2"}),"\n",(0,i.jsx)(n.li,{children:"Isaac ROS packages"}),"\n",(0,i.jsx)(n.li,{children:"TensorRT development libraries"}),"\n",(0,i.jsx)(n.li,{children:"Development tools (Git, Python 3.10+, build tools)"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"lab-setup",children:"Lab Setup"}),"\n",(0,i.jsx)(n.h3,{id:"environment-preparation",children:"Environment Preparation"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Verify Jetson Setup:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Check Jetson model and JetPack version\ncat /etc/nv_tegra_release\n\n# Check GPU status\nnvidia-smi\n\n# Check available memory\nfree -h\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Install Docker:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt update\nsudo apt install docker.io nvidia-docker2\nsudo systemctl restart docker\nsudo usermod -aG docker $USER\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Verify Docker with GPU support:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo docker run --rm --gpus all nvcr.io/nvidia/cuda:11.8-devel-ubuntu20.04 nvidia-smi\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"development-environment-setup",children:"Development Environment Setup"}),"\n",(0,i.jsx)(n.p,{children:"Create the project structure:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/edge_deployment_ws/{src,build,install,log}\ncd ~/edge_deployment_ws\n\n# Create Docker directory for container builds\nmkdir -p dockerfiles\nmkdir -p config\nmkdir -p scripts\n"})}),"\n",(0,i.jsx)(n.h2,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,i.jsx)(n.h3,{id:"step-1-containerized-application-structure",children:"Step 1: Containerized Application Structure"}),"\n",(0,i.jsx)(n.p,{children:"Create a Dockerfile optimized for Jetson deployment:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-dockerfile",children:'# dockerfiles/edge_robot_app.Dockerfile\nARG BASE_IMAGE=nvcr.io/nvidia/isaac-ros:galactic-ros-base-l4t-r35.2.1\nFROM ${BASE_IMAGE}\n\n# Set environment variables\nENV DEBIAN_FRONTEND=noninteractive\nENV NVIDIA_VISIBLE_DEVICES=all\nENV NVIDIA_DRIVER_CAPABILITIES=compute,utility\nENV PYTHONUNBUFFERED=1\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    python3-pip \\\n    python3-dev \\\n    build-essential \\\n    git \\\n    curl \\\n    vim \\\n    htop \\\n    iotop \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Upgrade pip\nRUN pip3 install --upgrade pip\n\n# Create application directory\nWORKDIR /app\n\n# Install Python dependencies\nCOPY requirements.txt .\nRUN pip3 install -r requirements.txt\n\n# Install application-specific dependencies\nRUN pip3 install \\\n    torch==1.13.0 \\\n    torchvision==0.14.0 \\\n    torchaudio==0.13.0 \\\n    --index-url https://download.pytorch.org/whl/l4t-cp38\n\n# Install TensorRT Python bindings\nRUN pip3 install nvidia-tensorrt --index-url https://pypi.ngc.nvidia.com\n\n# Copy application code\nCOPY src /app/src\nCOPY launch /app/launch\nCOPY config /app/config\n\n# Create non-root user for security\nRUN useradd -m -s /bin/bash robotuser && \\\n    usermod -aG dialout robotuser\n\n# Set ownership\nRUN chown -R robotuser:robotuser /app\nUSER robotuser\n\n# Set up ROS workspace\nCOPY ros_package /opt/ros_ws/src/edge_robot_app\nWORKDIR /opt/ros_ws\n\n# Build ROS package\nRUN source /opt/ros/galactic/setup.bash && \\\n    colcon build --packages-select edge_robot_app\n\n# Source ROS environment\nRUN echo "source /opt/ros/galactic/setup.bash" >> ~/.bashrc\nRUN echo "source /opt/ros_ws/install/setup.bash" >> ~/.bashrc\n\nWORKDIR /app\nCMD ["bash", "-c", "source /opt/ros/galactic/setup.bash && source /opt/ros_ws/install/setup.bash && python3 src/main.py"]\n'})}),"\n",(0,i.jsx)(n.p,{children:"Create requirements.txt for Python dependencies:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"# requirements.txt\nnumpy==1.21.6\nscipy==1.7.3\nopencv-python==4.6.0.66\nPillow==9.3.0\nrequests==2.28.1\npsutil==5.9.4\nGPUtil==1.4.0\ntorch-tensorrt==1.2.0\nnumba==0.56.4\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-2-tensorrt-model-optimization",children:"Step 2: TensorRT Model Optimization"}),"\n",(0,i.jsx)(n.p,{children:"Create a model optimization script:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# src/model_optimizer.py\n\nimport torch\nimport torch_tensorrt\nimport tensorrt as trt\nimport numpy as np\nimport logging\n\nclass ModelOptimizer:\n    def __init__(self, precision=\'fp16\', max_batch_size=1):\n        self.precision = precision\n        self.max_batch_size = max_batch_size\n        self.logger = logging.getLogger(__name__)\n\n    def optimize_torch_model(self, model, example_input, output_path):\n        """\n        Optimize PyTorch model using Torch-TensorRT\n        """\n        try:\n            # Set model to evaluation mode\n            model.eval()\n\n            # Trace the model\n            traced_model = torch.jit.trace(model, example_input)\n\n            # Compile with Torch-TensorRT\n            optimized_model = torch_tensorrt.compile(\n                traced_model,\n                inputs=[example_input],\n                enabled_precisions={torch.float, torch.half} if self.precision == \'fp16\' else {torch.float},\n                workspace_size=1 << 30,  # 1GB workspace\n                max_batch_size=self.max_batch_size\n            )\n\n            # Save optimized model\n            torch.jit.save(optimized_model, output_path)\n            self.logger.info(f"Model optimized and saved to {output_path}")\n\n            return optimized_model\n\n        except Exception as e:\n            self.logger.error(f"Error optimizing model: {e}")\n            return None\n\n    def optimize_with_tensorrt(self, onnx_model_path, output_path, input_shape):\n        """\n        Optimize ONNX model using native TensorRT\n        """\n        try:\n            # Create logger\n            logger = trt.Logger(trt.Logger.WARNING)\n            builder = trt.Builder(logger)\n            network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n            config = builder.create_builder_config()\n\n            # Parse ONNX model\n            parser = trt.OnnxParser(network, logger)\n            with open(onnx_model_path, \'rb\') as model_file:\n                if not parser.parse(model_file.read()):\n                    for error in range(parser.num_errors):\n                        self.logger.error(f"TensorRT Parser Error: {parser.get_error(error).desc()}")\n                    return False\n\n            # Configure optimization\n            if self.precision == \'fp16\':\n                config.set_flag(trt.BuilderFlag.FP16)\n            elif self.precision == \'int8\':\n                config.set_flag(trt.BuilderFlag.INT8)\n                # Add calibration here if needed\n\n            # Set workspace size\n            config.max_workspace_size = 1 << 30  # 1GB\n\n            # Build engine\n            serialized_engine = builder.build_serialized_network(network, config)\n\n            # Save engine\n            with open(output_path, \'wb\') as f:\n                f.write(serialized_engine)\n\n            self.logger.info(f"TensorRT engine saved to {output_path}")\n            return True\n\n        except Exception as e:\n            self.logger.error(f"Error creating TensorRT engine: {e}")\n            return False\n\n    def benchmark_model(self, model, input_tensor, num_runs=100):\n        """\n        Benchmark model performance\n        """\n        import time\n\n        # Warm up\n        for _ in range(10):\n            _ = model(input_tensor)\n\n        # Benchmark\n        times = []\n        for _ in range(num_runs):\n            start_time = time.time()\n            _ = model(input_tensor)\n            end_time = time.time()\n            times.append((end_time - start_time) * 1000)  # Convert to milliseconds\n\n        avg_time = sum(times) / len(times)\n        fps = 1000.0 / avg_time if avg_time > 0 else 0\n\n        self.logger.info(f"Model benchmark - Avg: {avg_time:.2f}ms, FPS: {fps:.2f}")\n        return avg_time, fps\n\n# Example usage\nif __name__ == "__main__":\n    # Example: Optimize a simple model\n    import torchvision.models as models\n\n    # Load a model\n    model = models.resnet18(pretrained=True)\n    example_input = torch.randn(1, 3, 224, 224).cuda()\n\n    optimizer = ModelOptimizer(precision=\'fp16\')\n\n    # Optimize the model\n    optimized_model = optimizer.optimize_torch_model(\n        model, example_input, "optimized_model.ts"\n    )\n\n    if optimized_model:\n        # Benchmark both models\n        print("Original model:")\n        optimizer.benchmark_model(model.cuda(), example_input)\n\n        print("Optimized model:")\n        optimizer.benchmark_model(optimized_model, example_input)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"step-3-resource-management-and-optimization",children:"Step 3: Resource Management and Optimization"}),"\n",(0,i.jsx)(n.p,{children:"Create a resource manager for efficient edge deployment:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# src/resource_manager.py\n\nimport psutil\nimport GPUtil\nimport threading\nimport time\nimport logging\nfrom collections import deque\nimport numpy as np\n\nclass ResourceManager:\n    def __init__(self, max_cpu_percent=80, max_gpu_percent=85, max_memory_percent=80):\n        self.max_cpu_percent = max_cpu_percent\n        self.max_gpu_percent = max_gpu_percent\n        self.max_memory_percent = max_memory_percent\n\n        self.monitoring = False\n        self.adaptation_enabled = True\n\n        self.cpu_history = deque(maxlen=30)  # 30 second history\n        self.gpu_history = deque(maxlen=30)\n        self.memory_history = deque(maxlen=30)\n\n        self.logger = logging.getLogger(__name__)\n        self.lock = threading.Lock()\n\n    def start_monitoring(self):\n        """Start resource monitoring in background thread"""\n        self.monitoring = True\n        self.monitor_thread = threading.Thread(target=self._monitor_loop)\n        self.monitor_thread.daemon = True\n        self.monitor_thread.start()\n\n    def _monitor_loop(self):\n        """Background monitoring loop"""\n        while self.monitoring:\n            try:\n                # Monitor CPU usage\n                cpu_percent = psutil.cpu_percent(interval=1)\n\n                # Monitor memory usage\n                memory_percent = psutil.virtual_memory().percent\n\n                # Monitor GPU usage (if available)\n                gpus = GPUtil.getGPUs()\n                if gpus:\n                    gpu_percent = gpus[0].load * 100  # Primary GPU\n                    gpu_memory_percent = gpus[0].memoryUtil * 100\n                else:\n                    gpu_percent = 0\n                    gpu_memory_percent = 0\n\n                # Store in history\n                with self.lock:\n                    self.cpu_history.append(cpu_percent)\n                    self.gpu_history.append(max(gpu_percent, gpu_memory_percent))\n                    self.memory_history.append(memory_percent)\n\n                # Check if adaptation is needed\n                if self.adaptation_enabled:\n                    self._check_adaptation_needed()\n\n            except Exception as e:\n                self.logger.error(f"Error in resource monitoring: {e}")\n\n    def _check_adaptation_needed(self):\n        """Check if resource adaptation is needed"""\n        with self.lock:\n            # Calculate recent averages\n            if len(self.cpu_history) > 0:\n                avg_cpu = sum(self.cpu_history) / len(self.cpu_history)\n            else:\n                avg_cpu = 0\n\n            if len(self.gpu_history) > 0:\n                avg_gpu = sum(self.gpu_history) / len(self.gpu_history)\n            else:\n                avg_gpu = 0\n\n            if len(self.memory_history) > 0:\n                avg_memory = sum(self.memory_history) / len(self.memory_history)\n            else:\n                avg_memory = 0\n\n        # Trigger adaptation if resources are overutilized\n        if (avg_cpu > self.max_cpu_percent or\n            avg_gpu > self.max_gpu_percent or\n            avg_memory > self.max_memory_percent):\n            self.logger.warning(f"Resource adaptation triggered: CPU={avg_cpu:.1f}%, GPU={avg_gpu:.1f}%, Memory={avg_memory:.1f}%")\n            self._perform_adaptation()\n\n    def _perform_adaptation(self):\n        """Perform resource adaptation"""\n        # This is where you\'d implement adaptation strategies\n        # Examples: reduce processing frequency, lower model precision, etc.\n        self.logger.info("Performing resource adaptation...")\n\n    def get_resource_stats(self):\n        """Get current resource utilization statistics"""\n        with self.lock:\n            if len(self.cpu_history) > 0:\n                cpu_stats = {\n                    \'current\': self.cpu_history[-1] if self.cpu_history else 0,\n                    \'average\': sum(self.cpu_history) / len(self.cpu_history) if self.cpu_history else 0,\n                    \'peak\': max(self.cpu_history) if self.cpu_history else 0\n                }\n            else:\n                cpu_stats = {\'current\': 0, \'average\': 0, \'peak\': 0}\n\n            if len(self.gpu_history) > 0:\n                gpu_stats = {\n                    \'current\': self.gpu_history[-1] if self.gpu_history else 0,\n                    \'average\': sum(self.gpu_history) / len(self.gpu_history) if self.gpu_history else 0,\n                    \'peak\': max(self.gpu_history) if self.gpu_history else 0\n                }\n            else:\n                gpu_stats = {\'current\': 0, \'average\': 0, \'peak\': 0}\n\n            if len(self.memory_history) > 0:\n                memory_stats = {\n                    \'current\': self.memory_history[-1] if self.memory_history else 0,\n                    \'average\': sum(self.memory_history) / len(self.memory_history) if self.memory_history else 0,\n                    \'peak\': max(self.memory_history) if self.memory_history else 0\n                }\n            else:\n                memory_stats = {\'current\': 0, \'average\': 0, \'peak\': 0}\n\n        return {\n            \'cpu\': cpu_stats,\n            \'gpu\': gpu_stats,\n            \'memory\': memory_stats\n        }\n\n    def stop_monitoring(self):\n        """Stop resource monitoring"""\n        self.monitoring = False\n        if hasattr(self, \'monitor_thread\'):\n            self.monitor_thread.join(timeout=2)\n\nclass MemoryManager:\n    def __init__(self, max_memory_mb=2048):\n        self.max_memory_mb = max_memory_mb\n        self.memory_pool = {}\n        self.current_allocation = 0\n        self.lock = threading.Lock()\n        self.logger = logging.getLogger(__name__)\n\n    def allocate_tensor(self, shape, dtype=np.float32):\n        """Efficiently allocate tensor with memory pooling"""\n        import torch\n\n        # Calculate memory requirement\n        element_size = np.dtype(dtype).itemsize\n        size_bytes = np.prod(shape) * element_size\n        size_mb = size_bytes / (1024 * 1024)\n\n        with self.lock:\n            if self.current_allocation + size_mb > self.max_memory_mb:\n                self.logger.warning(f"Memory allocation would exceed limit: {self.current_allocation + size_mb:.1f}MB / {self.max_memory_mb}MB")\n                # Try to free some memory or raise exception\n                self._try_free_memory(size_mb)\n\n            # Create tensor\n            tensor = torch.zeros(shape, dtype=torch.from_numpy(np.array([], dtype=dtype)).dtype, device=\'cuda\')\n            self.current_allocation += size_mb\n\n        return tensor\n\n    def _try_free_memory(self, needed_mb):\n        """Try to free memory by clearing cache"""\n        import torch\n        torch.cuda.empty_cache()\n        # Additional memory management strategies can be added here\n\n    def release_tensor(self, tensor):\n        """Release tensor back to pool"""\n        import torch\n        size_mb = tensor.numel() * tensor.element_size() / (1024 * 1024)\n\n        with self.lock:\n            self.current_allocation -= size_mb\n            tensor = None  # This should free the tensor\n\n    def get_memory_stats(self):\n        """Get memory usage statistics"""\n        import torch\n        allocated = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n        reserved = torch.cuda.memory_reserved() / (1024 * 1024)    # MB\n\n        return {\n            \'allocated_mb\': allocated,\n            \'reserved_mb\': reserved,\n            \'max_allowed_mb\': self.max_memory_mb,\n            \'utilization_percent\': (allocated / self.max_memory_mb) * 100 if self.max_memory_mb > 0 else 0\n        }\n'})}),"\n",(0,i.jsx)(n.h3,{id:"step-4-real-time-performance-optimization",children:"Step 4: Real-Time Performance Optimization"}),"\n",(0,i.jsx)(n.p,{children:"Create a real-time performance optimizer:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# src/performance_optimizer.py\n\nimport time\nimport threading\nimport logging\nfrom collections import deque\nimport subprocess\nimport os\n\nclass RealTimeOptimizer:\n    def __init__(self, target_frequency=30.0, max_latency_ms=33):\n        self.target_frequency = target_frequency\n        self.max_latency_ms = max_latency_ms\n        self.current_frequency = target_frequency\n\n        self.execution_times = deque(maxlen=100)\n        self.period_times = deque(maxlen=100)\n\n        self.logger = logging.getLogger(__name__)\n        self.adaptation_enabled = True\n\n        # CPU affinity for real-time performance\n        self.cpu_affinity = [0]  # Run on CPU 0\n\n    def configure_real_time(self):\n        """Configure real-time settings"""\n        try:\n            # Set CPU affinity\n            os.sched_setaffinity(0, self.cpu_affinity)\n            self.logger.info(f"Set CPU affinity to {self.cpu_affinity}")\n\n            # Try to set real-time priority (requires appropriate permissions)\n            try:\n                import ctypes\n                from ctypes import util\n                libc = ctypes.CDLL(util.find_library("c"))\n\n                # Try to set SCHED_FIFO with high priority\n                param = ctypes.c_int(80)  # High priority\n                result = libc.sched_setscheduler(\n                    os.getpid(),\n                    ctypes.c_int(1),  # SCHED_FIFO\n                    ctypes.byref(param)\n                )\n\n                if result == 0:\n                    self.logger.info("Set real-time scheduling (SCHED_FIFO)")\n                else:\n                    self.logger.warning("Could not set real-time scheduling")\n\n            except Exception as e:\n                self.logger.warning(f"Real-time scheduling setup failed: {e}")\n\n        except Exception as e:\n            self.logger.warning(f"Real-time configuration failed: {e}")\n\n    def start_performance_monitoring(self):\n        """Start performance monitoring in background"""\n        self.monitoring = True\n        self.monitor_thread = threading.Thread(target=self._monitor_performance)\n        self.monitor_thread.daemon = True\n        self.monitor_thread.start()\n\n    def _monitor_performance(self):\n        """Monitor performance in background"""\n        while self.monitoring:\n            if len(self.execution_times) > 10:\n                avg_execution = sum(self.execution_times) / len(self.execution_times)\n                max_execution = max(self.execution_times)\n\n                if max_execution > self.max_latency_ms:\n                    self.logger.warning(f"High latency detected: {max_execution:.2f}ms > {self.max_latency_ms}ms")\n\n                    if self.adaptation_enabled:\n                        self._adapt_performance()\n\n            time.sleep(1)  # Check every second\n\n    def _adapt_performance(self):\n        """Adapt performance parameters"""\n        if len(self.execution_times) > 10:\n            avg_execution = sum(self.execution_times) / len(self.execution_times)\n\n            # Adjust frequency based on performance\n            if avg_execution > self.max_latency_ms * 0.8:  # 80% of max latency\n                # Reduce frequency to ensure timing\n                self.current_frequency = max(10, self.current_frequency * 0.8)\n                self.logger.info(f"Reduced frequency to {self.current_frequency:.1f}Hz for timing compliance")\n            elif avg_execution < self.max_latency_ms * 0.5:  # 50% of max latency\n                # Can potentially increase frequency\n                self.current_frequency = min(self.target_frequency, self.current_frequency * 1.1)\n                self.logger.info(f"Increased frequency to {self.current_frequency:.1f}Hz")\n\n    def time_critical_loop(self, work_function, *args, **kwargs):\n        """Execute time-critical work with performance monitoring"""\n        start_time = time.perf_counter()\n\n        # Execute the work function\n        result = work_function(*args, **kwargs)\n\n        end_time = time.perf_counter()\n        execution_time_ms = (end_time - start_time) * 1000\n\n        # Record execution time\n        self.execution_times.append(execution_time_ms)\n\n        # Calculate required period\n        required_period_ms = 1000.0 / self.current_frequency\n\n        # Calculate sleep time to maintain frequency\n        sleep_time = (required_period_ms - execution_time_ms) / 1000.0\n\n        if sleep_time > 0:\n            time.sleep(sleep_time)\n        else:\n            # Missed deadline\n            self.logger.warning(f"Missed timing deadline: {execution_time_ms:.2f}ms > {required_period_ms:.2f}ms")\n\n        # Record actual period time\n        actual_end = time.perf_counter()\n        period_time_ms = (actual_end - start_time) * 1000\n        self.period_times.append(period_time_ms)\n\n        return result\n\n    def get_performance_stats(self):\n        """Get performance statistics"""\n        if len(self.execution_times) > 0:\n            avg_execution = sum(self.execution_times) / len(self.execution_times)\n            max_execution = max(self.execution_times)\n            min_execution = min(self.execution_times)\n        else:\n            avg_execution = max_execution = min_execution = 0\n\n        if len(self.period_times) > 0:\n            avg_period = sum(self.period_times) / len(self.period_times)\n        else:\n            avg_period = 0\n\n        return {\n            \'current_frequency\': self.current_frequency,\n            \'target_frequency\': self.target_frequency,\n            \'avg_execution_ms\': avg_execution,\n            \'max_execution_ms\': max_execution,\n            \'min_execution_ms\': min_execution,\n            \'avg_period_ms\': avg_period,\n            \'missed_deadlines\': sum(1 for t in self.execution_times if t > self.max_latency_ms)\n        }\n\n    def stop_monitoring(self):\n        """Stop performance monitoring"""\n        self.monitoring = False\n        if hasattr(self, \'monitor_thread\'):\n            self.monitor_thread.join(timeout=2)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"step-5-main-application-with-optimization",children:"Step 5: Main Application with Optimization"}),"\n",(0,i.jsx)(n.p,{children:"Create the main application file:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# src/main.py\n\n#!/usr/bin/env python3\n"""\nEdge Deployment Optimized Application\nThis application demonstrates optimized deployment techniques for Jetson platforms\n"""\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom geometry_msgs.msg import Twist\nfrom cv_bridge import CvBridge\nimport torch\nimport numpy as np\nfrom resource_manager import ResourceManager, MemoryManager\nfrom performance_optimizer import RealTimeOptimizer\nfrom model_optimizer import ModelOptimizer\nimport time\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass OptimizedEdgeApplication(Node):\n    def __init__(self):\n        super().__init__(\'optimized_edge_app\')\n\n        # Initialize components\n        self.cv_bridge = CvBridge()\n        self.resource_manager = ResourceManager()\n        self.memory_manager = MemoryManager(max_memory_mb=1024)\n        self.performance_optimizer = RealTimeOptimizer(target_frequency=20.0)\n\n        # Publishers and subscribers\n        self.image_sub = self.create_subscription(\n            Image, \'/camera/image_raw\', self.image_callback, 10\n        )\n        self.cmd_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n\n        # Initialize optimized model\n        self.model = None\n        self.initialize_optimized_model()\n\n        # Processing state\n        self.processing_enabled = True\n        self.frame_count = 0\n\n        # Start monitoring\n        self.resource_manager.start_monitoring()\n        self.performance_optimizer.start_performance_monitoring()\n\n        self.get_logger().info(\'Optimized Edge Application initialized\')\n\n    def initialize_optimized_model(self):\n        """Initialize optimized neural network model"""\n        try:\n            # Check if CUDA is available\n            if torch.cuda.is_available():\n                self.device = torch.device(\'cuda\')\n                logger.info("CUDA available, using GPU")\n            else:\n                self.device = torch.device(\'cpu\')\n                logger.warning("CUDA not available, using CPU")\n                return\n\n            # Load a pre-trained model (example: MobileNet for efficiency)\n            import torchvision.models as models\n            model = models.mobilenet_v2(pretrained=True)\n            model.eval()\n\n            # Create example input for tracing\n            example_input = torch.randn(1, 3, 224, 224, device=self.device)\n\n            # Optimize the model\n            optimizer = ModelOptimizer(precision=\'fp16\')\n            self.model = optimizer.optimize_torch_model(\n                model, example_input, "/tmp/optimized_model.ts"\n            )\n\n            if self.model is not None:\n                self.model = self.model.to(self.device)\n                logger.info("Model optimized and loaded successfully")\n            else:\n                logger.error("Failed to optimize model, falling back to CPU")\n                self.model = model.cpu()\n                self.device = torch.device(\'cpu\')\n\n        except Exception as e:\n            logger.error(f"Error initializing optimized model: {e}")\n            self.processing_enabled = False\n\n    def image_callback(self, msg):\n        """Process incoming image with optimization"""\n        if not self.processing_enabled:\n            return\n\n        try:\n            # Convert ROS image to tensor\n            cv_image = self.cv_bridge.imgmsg_to_cv2(msg, \'bgr8\')\n\n            # Preprocess image for model input\n            tensor_image = self.preprocess_image(cv_image)\n\n            # Process with optimized model\n            with torch.no_grad():\n                start_time = time.time()\n                result = self.model(tensor_image)\n                inference_time = (time.time() - start_time) * 1000  # ms\n\n            # Process results\n            self.process_inference_result(result, inference_time)\n\n            # Update frame count\n            self.frame_count += 1\n\n            # Log performance periodically\n            if self.frame_count % 50 == 0:\n                self.log_performance()\n\n        except Exception as e:\n            logger.error(f"Error processing image: {e}")\n\n    def preprocess_image(self, image):\n        """Preprocess image for model input"""\n        # Resize image to model input size\n        import cv2\n        resized = cv2.resize(image, (224, 224))\n\n        # Convert to tensor and normalize\n        tensor = torch.from_numpy(resized).permute(2, 0, 1).float()\n        tensor = tensor.unsqueeze(0).to(self.device) / 255.0\n\n        # Normalize with ImageNet means and stds\n        imagenet_mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(self.device)\n        imagenet_std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(self.device)\n\n        tensor = (tensor - imagenet_mean) / imagenet_std\n\n        return tensor\n\n    def process_inference_result(self, result, inference_time):\n        """Process model inference results"""\n        # Get top prediction\n        probabilities = torch.nn.functional.softmax(result[0], dim=0)\n        top_prob, top_cat = torch.topk(probabilities, 1)\n\n        # Log results (in a real application, you\'d use these for control)\n        if top_prob.item() > 0.5:  # Confidence threshold\n            self.get_logger().info(\n                f"Prediction: {top_cat.item()}, Confidence: {top_prob.item():.3f}, "\n                f"Inference time: {inference_time:.2f}ms"\n            )\n\n        # Publish a simple command based on inference\n        cmd = Twist()\n        cmd.linear.x = 0.2  # Move forward slowly\n        cmd.angular.z = 0.0  # No rotation\n        self.cmd_pub.publish(cmd)\n\n    def log_performance(self):\n        """Log performance statistics"""\n        # Get resource stats\n        resource_stats = self.resource_manager.get_resource_stats()\n\n        # Get memory stats\n        memory_stats = self.memory_manager.get_memory_stats()\n\n        # Get performance stats\n        perf_stats = self.performance_optimizer.get_performance_stats()\n\n        # Log all stats\n        self.get_logger().info(\n            f"Performance - Freq: {perf_stats[\'current_frequency\']:.1f}Hz, "\n            f"Exec: {perf_stats[\'avg_execution_ms\']:.2f}ms, "\n            f"CPU: {resource_stats[\'cpu\'][\'current\']:.1f}%, "\n            f"GPU: {resource_stats[\'gpu\'][\'current\']:.1f}%, "\n            f"Mem: {memory_stats[\'allocated_mb\']:.1f}MB"\n        )\n\n    def destroy_node(self):\n        """Clean up resources"""\n        self.resource_manager.stop_monitoring()\n        self.performance_optimizer.stop_monitoring()\n        super().destroy_node()\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    # Configure real-time settings\n    app = OptimizedEdgeApplication()\n    app.performance_optimizer.configure_real_time()\n\n    try:\n        rclpy.spin(app)\n    except KeyboardInterrupt:\n        app.get_logger().info(\'Shutting down optimized edge application\')\n    finally:\n        app.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"testing-and-validation",children:"Testing and Validation"}),"\n",(0,i.jsx)(n.h3,{id:"performance-testing-script",children:"Performance Testing Script"}),"\n",(0,i.jsx)(n.p,{children:"Create a comprehensive testing script:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# test_performance.py\n\nimport subprocess\nimport time\nimport json\nimport csv\nfrom datetime import datetime\n\ndef run_performance_test():\n    \"\"\"Run comprehensive performance test\"\"\"\n    results = {\n        'timestamp': datetime.now().isoformat(),\n        'tests': {}\n    }\n\n    # Test 1: Docker build time\n    print(\"Testing Docker build performance...\")\n    start_time = time.time()\n    try:\n        subprocess.run([\n            'docker', 'build',\n            '-f', 'dockerfiles/edge_robot_app.Dockerfile',\n            '-t', 'edge-robot-test:latest',\n            '.'\n        ], check=True, timeout=600)  # 10 minute timeout\n        build_time = time.time() - start_time\n        results['tests']['docker_build_time'] = build_time\n        print(f\"Docker build completed in {build_time:.2f}s\")\n    except subprocess.TimeoutExpired:\n        print(\"Docker build timed out\")\n        results['tests']['docker_build_time'] = -1\n    except subprocess.CalledProcessError as e:\n        print(f\"Docker build failed: {e}\")\n        results['tests']['docker_build_time'] = -1\n\n    # Test 2: Resource utilization\n    print(\"Testing resource utilization...\")\n    import psutil\n    import GPUtil\n\n    cpu_percent = psutil.cpu_percent(interval=1)\n    memory_percent = psutil.virtual_memory().percent\n\n    gpus = GPUtil.getGPUs()\n    if gpus:\n        gpu_percent = gpus[0].load * 100\n        gpu_memory_percent = gpus[0].memoryUtil * 100\n    else:\n        gpu_percent = gpu_memory_percent = 0\n\n    results['tests']['idle_cpu_percent'] = cpu_percent\n    results['tests']['idle_memory_percent'] = memory_percent\n    results['tests']['idle_gpu_percent'] = gpu_percent\n    results['tests']['idle_gpu_memory_percent'] = gpu_memory_percent\n\n    # Test 3: Model optimization performance\n    print(\"Testing model optimization...\")\n    import torch\n    import time\n\n    # Create a simple model for testing\n    model = torch.nn.Sequential(\n        torch.nn.Linear(1000, 512),\n        torch.nn.ReLU(),\n        torch.nn.Linear(512, 10)\n    ).cuda()\n    model.eval()\n\n    example_input = torch.randn(1, 1000).cuda()\n\n    # Test original model\n    start_time = time.time()\n    for _ in range(100):\n        with torch.no_grad():\n            _ = model(example_input)\n    original_time = (time.time() - start_time) / 100  # Average per inference\n\n    # Test with torch.jit optimization\n    traced_model = torch.jit.trace(model, example_input)\n    start_time = time.time()\n    for _ in range(100):\n        with torch.no_grad():\n            _ = traced_model(example_input)\n    traced_time = (time.time() - start_time) / 100  # Average per inference\n\n    results['tests']['original_model_time_ms'] = original_time * 1000\n    results['tests']['traced_model_time_ms'] = traced_time * 1000\n    results['tests']['optimization_improvement'] = (original_time - traced_time) / original_time * 100\n\n    # Save results\n    with open('performance_results.json', 'w') as f:\n        json.dump(results, f, indent=2)\n\n    print(\"Performance test completed. Results saved to performance_results.json\")\n    return results\n\nif __name__ == \"__main__\":\n    results = run_performance_test()\n\n    # Print summary\n    print(\"\\n=== Performance Test Summary ===\")\n    for test, result in results['tests'].items():\n        if isinstance(result, float):\n            print(f\"{test}: {result:.3f}\")\n        else:\n            print(f\"{test}: {result}\")\n"})}),"\n",(0,i.jsx)(n.h2,{id:"power-and-thermal-management",children:"Power and Thermal Management"}),"\n",(0,i.jsx)(n.p,{children:"Create a power management script:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# scripts/power_manager.py\n\n#!/usr/bin/env python3\n"""\nPower and thermal management for Jetson edge deployment\n"""\n\nimport subprocess\nimport time\nimport threading\nimport logging\n\nclass PowerManager:\n    def __init__(self):\n        self.logger = logging.getLogger(__name__)\n        self.monitoring = False\n        self.power_mode = \'balanced\'\n\n    def set_power_mode(self, mode):\n        """Set Jetson power mode"""\n        modes = {\n            \'max_performance\': \'MAXN\',\n            \'balanced\': \'MODE_15W\',  # Adjust based on your Jetson model\n            \'power_efficient\': \'MODE_10W\'\n        }\n\n        if mode in modes:\n            try:\n                subprocess.run([\'sudo\', \'nvpmodel\', \'-m\', modes[mode]], check=True)\n                self.power_mode = mode\n                self.logger.info(f"Set power mode to {mode}")\n                return True\n            except subprocess.CalledProcessError:\n                self.logger.error(f"Failed to set power mode {mode}")\n                return False\n        return False\n\n    def get_temperature(self):\n        """Get Jetson temperature"""\n        try:\n            with open(\'/sys/class/thermal/thermal_zone0/temp\', \'r\') as f:\n                temp_mC = int(f.read().strip())\n                return temp_mC / 1000.0  # Convert to Celsius\n        except Exception:\n            return 0.0\n\n    def start_thermal_protection(self):\n        """Start thermal monitoring and protection"""\n        self.monitoring = True\n        self.thermal_thread = threading.Thread(target=self._thermal_monitor_loop)\n        self.thermal_thread.daemon = True\n        self.thermal_thread.start()\n\n    def _thermal_monitor_loop(self):\n        """Thermal monitoring loop"""\n        max_temp = 85.0  # Celsius\n        hysteresis = 5.0\n\n        while self.monitoring:\n            current_temp = self.get_temperature()\n\n            if current_temp > max_temp:\n                self._activate_cooling()\n            elif current_temp < (max_temp - hysteresis):\n                self._restore_normal()\n\n            time.sleep(2)  # Check every 2 seconds\n\n    def _activate_cooling(self):\n        """Activate cooling measures"""\n        self.logger.warning(f"High temperature detected: {self.get_temperature():.1f}\xb0C")\n        # Reduce performance, activate fans, etc.\n        self.set_power_mode(\'power_efficient\')\n\n    def _restore_normal(self):\n        """Restore normal operation"""\n        if self.power_mode != \'balanced\':\n            self.set_power_mode(\'balanced\')\n\n    def start_power_logging(self):\n        """Start power consumption logging"""\n        self.power_logging = True\n        self.power_thread = threading.Thread(target=self._power_log_loop)\n        self.power_thread.daemon = True\n        self.power_thread.start()\n\n    def _power_log_loop(self):\n        """Power logging loop"""\n        while self.power_logging:\n            try:\n                # Read power consumption (example for Jetson Xavier)\n                with open(\'/sys/bus/i2c/devices/0-0040/hwmon/hwmon0/power1_input\', \'r\') as f:\n                    power_mw = int(f.read().strip())\n                    self.logger.info(f"Power consumption: {power_mw/1000:.2f}W")\n            except Exception:\n                pass  # Power monitoring not available on all Jetson models\n\n            time.sleep(10)  # Log every 10 seconds\n\ndef main():\n    power_manager = PowerManager()\n\n    # Set to balanced mode initially\n    power_manager.set_power_mode(\'balanced\')\n\n    # Start thermal protection\n    power_manager.start_thermal_protection()\n\n    # Start power logging\n    power_manager.start_power_logging()\n\n    try:\n        # Keep running\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        print("Shutting down power manager")\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"deployment-scripts",children:"Deployment Scripts"}),"\n",(0,i.jsx)(n.p,{children:"Create deployment scripts for easy deployment:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# scripts/deploy_jetson.sh\n\nset -e  # Exit on error\n\necho "Starting Jetson deployment..."\n\n# Check if running on Jetson\nif ! [ -f /etc/nv_tegra_release ]; then\n    echo "This script should be run on a Jetson device"\n    exit 1\nfi\n\n# Check prerequisites\nif ! command -v docker &> /dev/null; then\n    echo "Docker is required but not installed"\n    exit 1\nfi\n\nif ! nvidia-smi &> /dev/null; then\n    echo "NVIDIA drivers not found"\n    exit 1\nfi\n\n# Set power mode for optimal performance\necho "Setting power mode..."\nsudo nvpmodel -m MAXN\n\n# Configure Jetson clocks\necho "Configuring clocks..."\nsudo jetson_clocks\n\n# Build Docker image\necho "Building Docker image..."\ndocker build -f dockerfiles/edge_robot_app.Dockerfile -t edge-robot-app:latest .\n\n# Run the application with GPU access\necho "Starting application..."\ndocker run -it --rm \\\n    --gpus all \\\n    --privileged \\\n    --network host \\\n    --env NVIDIA_VISIBLE_DEVICES=all \\\n    --env NVIDIA_DRIVER_CAPABILITIES=compute,utility \\\n    --volume /tmp:/tmp \\\n    --device /dev:/dev \\\n    --device /dev/i2c-1:/dev/i2c-1 \\\n    edge-robot-app:latest\n\necho "Deployment completed!"\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# scripts/build_cross_platform.sh\n\nset -e\n\necho "Starting cross-platform build for Jetson..."\n\n# Check for NVIDIA Container Runtime\nif ! command -v nvidia-docker &> /dev/null; then\n    echo "NVIDIA Docker runtime is required"\n    exit 1\nfi\n\n# Build for Jetson architecture\necho "Building for aarch64 (Jetson)..."\ndocker buildx build \\\n    --platform linux/arm64 \\\n    -f dockerfiles/edge_robot_app.Dockerfile \\\n    -t edge-robot-app:latest \\\n    --load .\n\necho "Cross-platform build completed!"\n'})}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.h3,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Docker build fails with memory issues:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Increase swap space on Jetson"}),"\n",(0,i.jsxs)(n.li,{children:["Build with reduced parallelism: ",(0,i.jsx)(n.code,{children:"docker build --memory=2g"})]}),"\n",(0,i.jsx)(n.li,{children:"Use build cache effectively"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Model optimization fails:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Check TensorRT version compatibility"}),"\n",(0,i.jsx)(n.li,{children:"Verify GPU memory availability"}),"\n",(0,i.jsx)(n.li,{children:"Use appropriate precision (FP16 vs INT8)"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"High power consumption:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use power-efficient inference modes"}),"\n",(0,i.jsx)(n.li,{children:"Reduce processing frequency when possible"}),"\n",(0,i.jsx)(n.li,{children:"Implement adaptive performance scaling"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Thermal throttling:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Improve cooling solution"}),"\n",(0,i.jsx)(n.li,{children:"Use power management scripts"}),"\n",(0,i.jsx)(n.li,{children:"Optimize algorithms for efficiency"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"lab-deliverables",children:"Lab Deliverables"}),"\n",(0,i.jsx)(n.p,{children:"Complete the following tasks to finish the lab:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Containerize the application"})," using the provided Dockerfile"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Implement model optimization"})," with TensorRT"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Create resource management"})," system with monitoring"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deploy and test"})," on Jetson hardware"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Document your results"})," including:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Performance improvements achieved"}),"\n",(0,i.jsx)(n.li,{children:"Resource utilization statistics"}),"\n",(0,i.jsx)(n.li,{children:"Power consumption measurements"}),"\n",(0,i.jsx)(n.li,{children:"Any challenges encountered and solutions"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"assessment-criteria",children:"Assessment Criteria"}),"\n",(0,i.jsx)(n.p,{children:"Your lab implementation will be assessed based on:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Functionality"}),": Does the optimized application work correctly?"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Performance"}),": Are optimization improvements significant?"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Efficiency"}),": How well does it manage resources?"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Code Quality"}),": Is the code well-structured and documented?"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Problem Solving"}),": How effectively did you optimize for edge constraints?"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"extensions-optional",children:"Extensions (Optional)"}),"\n",(0,i.jsx)(n.p,{children:"For advanced students, consider implementing:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Adaptive precision scaling"})," based on available resources"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multi-model optimization"})," with shared resources"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Edge-cloud hybrid deployment"})," strategies"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Real-time performance prediction"})," and adaptation"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"This lab provided hands-on experience with edge deployment optimization for Isaac-based robotic applications. You learned to containerize applications, optimize neural networks with TensorRT, manage system resources efficiently, and deploy applications with appropriate power and thermal management. These skills are essential for deploying robotic systems in resource-constrained edge environments."})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453(e,n,t){t.d(n,{R:()=>s,x:()=>l});var r=t(6540);const i={},o=r.createContext(i);function s(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);