"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[3098],{8453(e,n,i){i.d(n,{R:()=>s,x:()=>o});var t=i(6540);const r={},a=t.createContext(r);function s(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(a.Provider,{value:n},e.children)}},9619(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"module-2/sim-to-real","title":"Sim-to-Real Transfer Challenges","description":"Overview","source":"@site/docs/module-2/sim-to-real.md","sourceDirName":"module-2","slug":"/module-2/sim-to-real","permalink":"/hackathon/docs/module-2/sim-to-real","draft":false,"unlisted":false,"editUrl":"https://github.com/Fatimaali424/hackathon/edit/main/website/docs/module-2/sim-to-real.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Unity Integration & Advanced Visualization","permalink":"/hackathon/docs/module-2/unity-integration"},"next":{"title":"Lab 4: Basic Robot Model and Simulation","permalink":"/hackathon/docs/module-2/lab-4-robot-model"}}');var r=i(4848),a=i(8453);const s={sidebar_position:6},o="Sim-to-Real Transfer Challenges",l={},d=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Understanding the Reality Gap",id:"understanding-the-reality-gap",level:2},{value:"Physical Properties",id:"physical-properties",level:3},{value:"Sensor Characteristics",id:"sensor-characteristics",level:3},{value:"Environmental Factors",id:"environmental-factors",level:3},{value:"Domain Randomization",id:"domain-randomization",level:2},{value:"Visual Domain Randomization",id:"visual-domain-randomization",level:3},{value:"Physical Domain Randomization",id:"physical-domain-randomization",level:3},{value:"System Identification",id:"system-identification",level:2},{value:"Black-Box System Identification",id:"black-box-system-identification",level:3},{value:"Parameter Estimation",id:"parameter-estimation",level:3},{value:"Robust Control Design",id:"robust-control-design",level:2},{value:"Robust PID Control",id:"robust-pid-control",level:3},{value:"Adaptive Control",id:"adaptive-control",level:3},{value:"Simulation Fidelity Enhancement",id:"simulation-fidelity-enhancement",level:2},{value:"High-Fidelity Physics Modeling",id:"high-fidelity-physics-modeling",level:3},{value:"Sensor Noise Modeling",id:"sensor-noise-modeling",level:3},{value:"Transfer Learning Techniques",id:"transfer-learning-techniques",level:2},{value:"Progressive Domain Transfer",id:"progressive-domain-transfer",level:3},{value:"Domain Adaptation Networks",id:"domain-adaptation-networks",level:3},{value:"Evaluation Metrics",id:"evaluation-metrics",level:2},{value:"Transfer Success Rate",id:"transfer-success-rate",level:3},{value:"Performance Degradation Metrics",id:"performance-degradation-metrics",level:3},{value:"Best Practices for Sim-to-Real Transfer",id:"best-practices-for-sim-to-real-transfer",level:2},{value:"Simulation Design Guidelines",id:"simulation-design-guidelines",level:3},{value:"Control Strategy Guidelines",id:"control-strategy-guidelines",level:3},{value:"Testing Protocol",id:"testing-protocol",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Low Transfer Success Rates",id:"low-transfer-success-rates",level:3},{value:"High Variance in Real Performance",id:"high-variance-in-real-performance",level:3},{value:"Summary",id:"summary",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"sim-to-real-transfer-challenges",children:"Sim-to-Real Transfer Challenges"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:'The transition from simulation to real-world robotic systems presents significant challenges that must be carefully addressed to ensure successful deployment. This chapter explores the "reality gap" between simulation and real-world environments, strategies for minimizing this gap, and techniques for achieving robust sim-to-real transfer.'}),"\n",(0,r.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Identify the key factors contributing to the reality gap"}),"\n",(0,r.jsx)(n.li,{children:"Apply domain randomization and system identification techniques"}),"\n",(0,r.jsx)(n.li,{children:"Implement robust control strategies that work in both simulation and reality"}),"\n",(0,r.jsx)(n.li,{children:"Evaluate sim-to-real transfer performance and identify failure modes"}),"\n",(0,r.jsx)(n.li,{children:"Design simulation environments that maximize transferability"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"understanding-the-reality-gap",children:"Understanding the Reality Gap"}),"\n",(0,r.jsx)(n.p,{children:"The reality gap refers to the differences between simulated and real-world environments that can cause behaviors learned or tested in simulation to fail when deployed on physical robots. These differences manifest in multiple dimensions:"}),"\n",(0,r.jsx)(n.h3,{id:"physical-properties",children:"Physical Properties"}),"\n",(0,r.jsx)(n.p,{children:"Real-world physics often differs from simulation in subtle but critical ways:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Friction coefficients"}),": Real surfaces have variable friction that's difficult to model precisely"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Mass properties"}),": Actual robot masses may differ from CAD estimates"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Inertial properties"}),": Center of mass and moments of inertia may not match models"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Actuator dynamics"}),": Real motors have non-linear responses, delays, and limitations"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"sensor-characteristics",children:"Sensor Characteristics"}),"\n",(0,r.jsx)(n.p,{children:"Real sensors exhibit behaviors not captured in idealized simulation models:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Noise patterns"}),": Real sensors have complex noise characteristics"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Latency"}),": Communication and processing delays affect real-time performance"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Calibration errors"}),": Imperfect calibration affects measurement accuracy"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Environmental factors"}),": Lighting, temperature, and interference affect performance"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"environmental-factors",children:"Environmental Factors"}),"\n",(0,r.jsx)(n.p,{children:"Real-world environments have complexities not present in controlled simulations:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamic obstacles"}),": Moving objects and changing environments"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lighting conditions"}),": Varying illumination affects vision-based systems"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Surface variations"}),": Uneven terrain, different materials, obstacles"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"External disturbances"}),": Wind, vibrations, electromagnetic interference"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,r.jsx)(n.p,{children:"Domain randomization is a technique that improves sim-to-real transfer by training systems across a wide range of randomized simulation conditions:"}),"\n",(0,r.jsx)(n.h3,{id:"visual-domain-randomization",children:"Visual Domain Randomization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Example of visual domain randomization in Unity or Gazebo\ndef randomize_visual_properties():\n    # Randomize lighting conditions\n    light_intensity = np.random.uniform(0.5, 2.0)\n    light_temperature = np.random.uniform(3000, 8000)  # Kelvin\n\n    # Randomize material properties\n    albedo = np.random.uniform(0.1, 1.0, size=3)  # RGB\n    roughness = np.random.uniform(0.0, 1.0)\n    metallic = np.random.uniform(0.0, 1.0)\n\n    # Randomize camera parameters\n    exposure = np.random.uniform(0.5, 1.5)\n    contrast = np.random.uniform(0.8, 1.2)\n\n    return {\n        'light_intensity': light_intensity,\n        'light_temperature': light_temperature,\n        'albedo': albedo,\n        'roughness': roughness,\n        'metallic': metallic,\n        'exposure': exposure,\n        'contrast': contrast\n    }\n"})}),"\n",(0,r.jsx)(n.h3,{id:"physical-domain-randomization",children:"Physical Domain Randomization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Randomizing physical properties for sim-to-real transfer\ndef randomize_physical_properties():\n    # Robot mass variations\n    base_mass = nominal_mass * np.random.uniform(0.95, 1.05)\n\n    # Friction coefficients\n    ground_friction = np.random.uniform(0.4, 1.2)\n    wheel_friction = np.random.uniform(0.6, 1.0)\n\n    # Actuator parameters\n    motor_constant = nominal_motor_constant * np.random.uniform(0.9, 1.1)\n    gear_ratio = nominal_gear_ratio * np.random.uniform(0.99, 1.01)\n\n    # Sensor noise parameters\n    imu_noise = np.random.uniform(1e-4, 1e-3)\n    encoder_noise = np.random.uniform(0.001, 0.01)\n\n    return {\n        'base_mass': base_mass,\n        'ground_friction': ground_friction,\n        'wheel_friction': wheel_friction,\n        'motor_constant': motor_constant,\n        'gear_ratio': gear_ratio,\n        'imu_noise': imu_noise,\n        'encoder_noise': encoder_noise\n    }\n"})}),"\n",(0,r.jsx)(n.h2,{id:"system-identification",children:"System Identification"}),"\n",(0,r.jsx)(n.p,{children:"System identification involves characterizing real-world robot dynamics to improve simulation accuracy:"}),"\n",(0,r.jsx)(n.h3,{id:"black-box-system-identification",children:"Black-Box System Identification"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom scipy import signal\nimport matplotlib.pyplot as plt\n\ndef identify_robot_dynamics(input_signal, output_signal, sampling_time):\n    """\n    Identify robot dynamics using input-output data\n    """\n    # Estimate transfer function using prediction error method\n    system_order = 4  # Adjust based on complexity\n\n    # Convert to discrete-time transfer function\n    num, den = signal.bilinear([1], [1, 1], fs=1/sampling_time)\n\n    # Use system identification techniques\n    # This is a simplified example - real implementation would use more sophisticated methods\n    estimated_sys = signal.TransferFunction(num, den, dt=sampling_time)\n\n    return estimated_sys\n\ndef validate_model(identified_system, validation_input, actual_output):\n    """\n    Validate the identified model against validation data\n    """\n    # Simulate the identified model\n    _, simulated_output = signal.dlsim(identified_system, validation_input)\n\n    # Calculate validation metrics\n    mse = np.mean((actual_output - simulated_output.flatten())**2)\n    rmse = np.sqrt(mse)\n\n    # Calculate fit percentage\n    ss_res = np.sum((actual_output - simulated_output.flatten())**2)\n    ss_tot = np.sum((actual_output - np.mean(actual_output))**2)\n    fit_percent = 100 * (1 - (ss_res / ss_tot))\n\n    return {\n        \'mse\': mse,\n        \'rmse\': rmse,\n        \'fit_percent\': fit_percent,\n        \'simulated_output\': simulated_output\n    }\n'})}),"\n",(0,r.jsx)(n.h3,{id:"parameter-estimation",children:"Parameter Estimation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def estimate_robot_parameters(robot_model, experimental_data):\n    \"\"\"\n    Estimate robot parameters using experimental data\n    \"\"\"\n    from scipy.optimize import minimize\n\n    def objective_function(params):\n        # Update model with current parameters\n        robot_model.update_parameters(params)\n\n        # Simulate with current parameters\n        simulated_trajectory = robot_model.simulate(\n            experimental_data['input'])\n\n        # Calculate error with actual data\n        error = np.sum((simulated_trajectory -\n                       experimental_data['output'])**2)\n\n        return error\n\n    # Initial parameter guess\n    initial_params = robot_model.get_nominal_parameters()\n\n    # Optimize parameters\n    result = minimize(objective_function, initial_params,\n                     method='BFGS')\n\n    return result.x\n"})}),"\n",(0,r.jsx)(n.h2,{id:"robust-control-design",children:"Robust Control Design"}),"\n",(0,r.jsx)(n.p,{children:"Designing controllers that work well in both simulation and reality requires robustness considerations:"}),"\n",(0,r.jsx)(n.h3,{id:"robust-pid-control",children:"Robust PID Control"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class RobustPIDController:\n    def __init__(self, kp, ki, kd, sample_time=0.01):\n        self.kp = kp\n        self.ki = ki\n        self.kd = kd\n        self.sample_time = sample_time\n\n        # Internal state\n        self.integral = 0\n        self.previous_error = 0\n        self.previous_derivative = 0\n\n        # Anti-windup and filtering\n        self.integral_limit = 10.0\n        self.derivative_filter = 0.1\n\n    def update(self, error):\n        # Proportional term\n        p_term = self.kp * error\n\n        # Integral term with anti-windup\n        self.integral += error * self.sample_time\n        self.integral = np.clip(self.integral,\n                               -self.integral_limit,\n                               self.integral_limit)\n        i_term = self.ki * self.integral\n\n        # Derivative term with filtering to reduce noise\n        derivative_raw = (error - self.previous_error) / self.sample_time\n        derivative_filtered = (self.derivative_filter * self.previous_derivative +\n                              (1 - self.derivative_filter) * derivative_raw)\n        d_term = self.kd * derivative_filtered\n\n        # Store for next iteration\n        self.previous_error = error\n        self.previous_derivative = derivative_filtered\n\n        # Calculate output\n        output = p_term + i_term + d_term\n        return output\n"})}),"\n",(0,r.jsx)(n.h3,{id:"adaptive-control",children:"Adaptive Control"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class ModelReferenceAdaptiveController:\n    def __init__(self, reference_model, initial_params):\n        self.reference_model = reference_model\n        self.params = initial_params\n        self.param_adaptation_gain = 0.01\n\n    def update(self, state_error, regressor_vector):\n        """\n        Update controller parameters based on tracking error\n        """\n        # Calculate control law\n        control_signal = -np.dot(self.params, regressor_vector)\n\n        # Parameter adaptation law (Gradient descent)\n        param_update = (self.param_adaptation_gain *\n                       state_error * regressor_vector)\n\n        # Update parameters\n        self.params += param_update\n\n        return control_signal\n'})}),"\n",(0,r.jsx)(n.h2,{id:"simulation-fidelity-enhancement",children:"Simulation Fidelity Enhancement"}),"\n",(0,r.jsx)(n.p,{children:"Improving simulation fidelity to reduce the reality gap:"}),"\n",(0,r.jsx)(n.h3,{id:"high-fidelity-physics-modeling",children:"High-Fidelity Physics Modeling"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Enhanced SDF model with detailed physics properties --\x3e\n<model name="high_fidelity_robot">\n  <link name="base_link">\n    <inertial>\n      \x3c!-- Precise mass properties from CAD model --\x3e\n      <mass>2.5</mass>\n      <inertia>\n        <ixx>0.012</ixx>\n        <ixy>-0.001</ixy>\n        <ixz>0.002</ixz>\n        <iyy>0.018</iyy>\n        <iyz>-0.001</iyz>\n        <izz>0.022</izz>\n      </inertia>\n    </inertial>\n\n    <collision name="collision">\n      <surface>\n        <friction>\n          <ode>\n            <mu>0.8</mu>\n            <mu2>0.8</mu2>\n            <fdir1>0 0 1</fdir1>\n            <slip1>0.0</slip1>\n            <slip2>0.0</slip2>\n          </ode>\n          <torsional>\n            <coefficient>0.1</coefficient>\n            <use_patch_radius>false</use_patch_radius>\n            <surface_radius>0.01</surface_radius>\n          </torsional>\n        </friction>\n        <bounce>\n          <restitution_coefficient>0.1</restitution_coefficient>\n          <threshold>100000</threshold>\n        </bounce>\n        <contact>\n          <ode>\n            <soft_cfm>0</soft_cfm>\n            <soft_erp>0.2</soft_erp>\n            <kp>1e+13</kp>\n            <kd>1</kd>\n            <max_vel>100.0</max_vel>\n            <min_depth>0.001</min_depth>\n          </ode>\n        </contact>\n      </surface>\n    </collision>\n\n    <visual name="visual">\n      <geometry>\n        <mesh>\n          <uri>model://robot/meshes/base.dae</uri>\n        </mesh>\n      </geometry>\n      <material>\n        <script>\n          <uri>file://media/materials/scripts/gazebo.material</uri>\n          <name>Gazebo/Orange</name>\n        <\/script>\n      </material>\n    </visual>\n  </link>\n</model>\n'})}),"\n",(0,r.jsx)(n.h3,{id:"sensor-noise-modeling",children:"Sensor Noise Modeling"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class RealisticSensorModel:\n    def __init__(self, base_noise, bias_drift_rate, quantization_levels):\n        self.base_noise = base_noise\n        self.bias_drift_rate = bias_drift_rate\n        self.quantization_levels = quantization_levels\n\n        # Initialize bias drift\n        self.current_bias = 0.0\n\n    def add_realistic_noise(self, true_value, dt):\n        """\n        Add realistic noise to sensor measurements\n        """\n        # Base measurement noise\n        noise = np.random.normal(0, self.base_noise)\n\n        # Bias drift (slowly varying offset)\n        self.current_bias += np.random.normal(0, self.bias_drift_rate * dt)\n\n        # Quantization effects\n        quantized_value = self.quantize(true_value + noise + self.current_bias,\n                                      self.quantization_levels)\n\n        return quantized_value\n\n    def quantize(self, value, levels):\n        """\n        Simulate quantization effects\n        """\n        step = (np.max(levels) - np.min(levels)) / len(levels)\n        quantized = np.round(value / step) * step\n        return np.clip(quantized, np.min(levels), np.max(levels))\n'})}),"\n",(0,r.jsx)(n.h2,{id:"transfer-learning-techniques",children:"Transfer Learning Techniques"}),"\n",(0,r.jsx)(n.h3,{id:"progressive-domain-transfer",children:"Progressive Domain Transfer"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def progressive_domain_transfer(initial_sim_env, target_env,\n                              training_episodes=1000):\n    \"\"\"\n    Gradually transfer from simulation to reality\n    \"\"\"\n    # Start with basic simulation\n    current_env = initial_sim_env\n    transfer_schedule = [\n        {'domain_randomization': 0.1, 'episode_count': 200},\n        {'domain_randomization': 0.3, 'episode_count': 200},\n        {'domain_randomization': 0.5, 'episode_count': 200},\n        {'domain_randomization': 0.7, 'episode_count': 200},\n        {'domain_randomization': 0.9, 'episode_count': 200},\n    ]\n\n    policy = initialize_policy()\n\n    for stage_params in transfer_schedule:\n        # Train in current domain\n        policy = train_policy(policy, current_env,\n                            episodes=stage_params['episode_count'])\n\n        # Increase domain randomization\n        current_env.set_domain_randomization(\n            stage_params['domain_randomization'])\n\n    return policy\n"})}),"\n",(0,r.jsx)(n.h3,{id:"domain-adaptation-networks",children:"Domain Adaptation Networks"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import torch\nimport torch.nn as nn\n\nclass DomainAdaptationNetwork(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(DomainAdaptationNetwork, self).__init__()\n\n        # Feature extractor\n        self.feature_extractor = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU()\n        )\n\n        # Task-specific classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, output_dim)\n        )\n\n        # Domain classifier\n        self.domain_classifier = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x, alpha=0.0):\n        features = self.feature_extractor(x)\n\n        # Reverse gradient for domain adaptation\n        reversed_features = GradientReversalFunction.apply(features, alpha)\n\n        task_output = self.classifier(features)\n        domain_output = self.domain_classifier(reversed_features)\n\n        return task_output, domain_output\n\nclass GradientReversalFunction(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, input, alpha):\n        ctx.alpha = alpha\n        return input\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output = grad_output.neg() * ctx.alpha\n        return output, None\n"})}),"\n",(0,r.jsx)(n.h2,{id:"evaluation-metrics",children:"Evaluation Metrics"}),"\n",(0,r.jsx)(n.p,{children:"Quantitative evaluation of sim-to-real transfer:"}),"\n",(0,r.jsx)(n.h3,{id:"transfer-success-rate",children:"Transfer Success Rate"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def evaluate_transfer_success(sim_policy, real_robot, test_scenarios):\n    """\n    Evaluate how well a policy trained in simulation works on a real robot\n    """\n    success_count = 0\n    total_trials = len(test_scenarios)\n\n    for scenario in test_scenarios:\n        # Reset robot to scenario start state\n        real_robot.reset(scenario.start_state)\n\n        # Execute policy\n        trajectory = execute_policy(real_robot, sim_policy,\n                                  scenario.goal, scenario.max_steps)\n\n        # Check if goal reached\n        if check_goal_reached(trajectory, scenario.goal):\n            success_count += 1\n\n    transfer_success_rate = success_count / total_trials\n    return transfer_success_rate\n'})}),"\n",(0,r.jsx)(n.h3,{id:"performance-degradation-metrics",children:"Performance Degradation Metrics"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def calculate_performance_metrics(sim_performance, real_performance):\n    \"\"\"\n    Calculate metrics to quantify sim-to-real performance degradation\n    \"\"\"\n    # Absolute performance difference\n    performance_gap = sim_performance - real_performance\n\n    # Relative degradation\n    relative_degradation = (performance_gap / sim_performance) * 100\n\n    # Robustness metric (variance across trials)\n    real_performance_variance = np.var(real_performance_trials)\n\n    return {\n        'performance_gap': performance_gap,\n        'relative_degradation': relative_degradation,\n        'robustness_metric': real_performance_variance,\n        'transfer_efficiency': real_performance / sim_performance\n    }\n"})}),"\n",(0,r.jsx)(n.h2,{id:"best-practices-for-sim-to-real-transfer",children:"Best Practices for Sim-to-Real Transfer"}),"\n",(0,r.jsx)(n.h3,{id:"simulation-design-guidelines",children:"Simulation Design Guidelines"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Accurate modeling"}),": Include all relevant physical phenomena"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor realism"}),": Model noise, latency, and limitations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Environmental complexity"}),": Include realistic disturbances"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Validation"}),": Continuously validate against real robot data"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"control-strategy-guidelines",children:"Control Strategy Guidelines"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Robust design"}),": Design controllers that handle uncertainty"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Adaptive approaches"}),": Use adaptive or learning-based controllers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Safety margins"}),": Include safety margins in control design"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gradual deployment"}),": Test incrementally in increasingly realistic conditions"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"testing-protocol",children:"Testing Protocol"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simulation validation"}),": Validate in simulation first"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Safety checks"}),": Implement safety checks before real-world testing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gradual complexity"}),": Start with simple tasks and increase complexity"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data collection"}),": Collect data to improve models and controllers"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,r.jsx)(n.h3,{id:"low-transfer-success-rates",children:"Low Transfer Success Rates"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Check model accuracy"}),": Verify that simulation models match reality"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Increase domain randomization"}),": Add more randomization to training"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Review sensor models"}),": Ensure sensor noise and delays are realistic"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Analyze failure modes"}),": Identify specific failure patterns"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"high-variance-in-real-performance",children:"High Variance in Real Performance"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implement robust control"}),": Add robustness to control algorithms"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reduce model mismatch"}),": Improve system identification"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Add safety constraints"}),": Implement constraints to limit risky behaviors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Increase training diversity"}),": Train with more varied conditions"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(n.p,{children:"This chapter explored the critical challenges of transferring robotic systems from simulation to reality. We examined the sources of the reality gap, techniques for reducing it through domain randomization and system identification, and strategies for designing robust controllers that work in both domains. Successful sim-to-real transfer requires careful attention to modeling accuracy, sensor realism, and robust control design."}),"\n",(0,r.jsx)(n.p,{children:"In the next module, we'll explore NVIDIA Isaac as the AI-powered brain for robotic systems, building on the simulation foundations we've established."})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);