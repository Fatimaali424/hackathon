"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[8634],{2110(n,e,t){t.r(e),t.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"capstone/navigation","title":"Navigation System Integration","description":"Overview","source":"@site/docs/capstone/navigation.md","sourceDirName":"capstone","slug":"/capstone/navigation","permalink":"/hackathon/docs/capstone/navigation","draft":false,"unlisted":false,"editUrl":"https://github.com/Fatimaali424/hackathon/edit/main/website/docs/capstone/navigation.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Planning System Integration","permalink":"/hackathon/docs/capstone/planning"},"next":{"title":"Perception System Integration","permalink":"/hackathon/docs/capstone/perception"}}');var o=t(4848),i=t(8453);const s={sidebar_position:4},l="Navigation System Integration",r={},c=[{value:"Overview",id:"overview",level:2},{value:"Navigation Architecture",id:"navigation-architecture",level:2},{value:"Navigation System Components",id:"navigation-system-components",level:3},{value:"Localization System",id:"localization-system",level:2},{value:"Robot Localization",id:"robot-localization",level:3},{value:"Path Planning System",id:"path-planning-system",level:2},{value:"Global and Local Path Planning",id:"global-and-local-path-planning",level:3},{value:"Local Path Planning and Obstacle Avoidance",id:"local-path-planning-and-obstacle-avoidance",level:2},{value:"Dynamic Window Approach (DWA)",id:"dynamic-window-approach-dwa",level:3},{value:"Navigation Integration",id:"navigation-integration",level:2},{value:"Complete Navigation System",id:"complete-navigation-system",level:3},{value:"Integration with Voice Command System",id:"integration-with-voice-command-system",level:2},{value:"Navigation Command Handler",id:"navigation-command-handler",level:3},{value:"Safety and Recovery",id:"safety-and-recovery",level:2},{value:"Navigation Safety Systems",id:"navigation-safety-systems",level:3}];function _(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,i.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"navigation-system-integration",children:"Navigation System Integration"})}),"\n",(0,o.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(e.p,{children:"The navigation system is a critical component of the autonomous humanoid robot, enabling it to move safely and efficiently through complex environments. This system must handle various navigation challenges including obstacle avoidance, path planning, localization, and dynamic replanning in response to environmental changes. The navigation system integrates with other modules to provide seamless mobility as part of the complete voice-command-to-action pipeline."}),"\n",(0,o.jsx)(e.p,{children:"The navigation system follows the ROS 2 Navigation2 framework while incorporating specialized capabilities for humanoid robotics applications, including integration with perception systems for enhanced environmental understanding and dynamic obstacle avoidance."}),"\n",(0,o.jsx)(e.h2,{id:"navigation-architecture",children:"Navigation Architecture"}),"\n",(0,o.jsx)(e.h3,{id:"navigation-system-components",children:"Navigation System Components"}),"\n",(0,o.jsx)(e.p,{children:"The navigation system consists of several interconnected components:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    COMMAND INTERPRETATION                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Command         \u2502  \u2502 Intent          \u2502  \u2502 Goal            \u2502 \u2502\n\u2502  \u2502 Reception       \u2502  \u2502 Classification  \u2502  \u2502 Transformation  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      LOCALIZATION SYSTEM                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Map Loading     \u2502  \u2502 Pose            \u2502  \u2502 AMCL            \u2502 \u2502\n\u2502  \u2502                 \u2502  \u2502 Estimation      \u2502  \u2502 Localization    \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       MAPPING SYSTEM                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Occupancy       \u2502  \u2502 Costmap         \u2502  \u2502 Global Map      \u2502 \u2502\n\u2502  \u2502 Mapping         \u2502  \u2502 Generation      \u2502  \u2502 Management      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      PATH PLANNING                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Global Planner  \u2502  \u2502 Local Planner   \u2502  \u2502 Path            \u2502 \u2502\n\u2502  \u2502 (A*)            \u2502  \u2502 (DWA/TEB)       \u2502  \u2502 Smoothing       \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     MOTION CONTROL                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Velocity        \u2502  \u2502 Obstacle        \u2502  \u2502 Safety          \u2502 \u2502\n\u2502  \u2502 Commands        \u2502  \u2502 Avoidance       \u2502  \u2502 Monitoring      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     ROBOT HARDWARE                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Wheel Encoders  \u2502  \u2502 IMU             \u2502  \u2502 Motor Control   \u2502 \u2502\n\u2502  \u2502 Odometry        \u2502  \u2502 Sensors         \u2502  \u2502 Interface       \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,o.jsx)(e.h2,{id:"localization-system",children:"Localization System"}),"\n",(0,o.jsx)(e.h3,{id:"robot-localization",children:"Robot Localization"}),"\n",(0,o.jsx)(e.p,{children:"The localization system determines the robot's position and orientation in the environment:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport math\nfrom typing import Tuple, List, Optional\nimport threading\nfrom dataclasses import dataclass\n\n@dataclass\nclass Pose2D:\n    """2D pose representation (x, y, theta)"""\n    x: float\n    y: float\n    theta: float  # in radians\n\n@dataclass\nclass Particle:\n    """Particle for Monte Carlo Localization"""\n    x: float\n    y: float\n    theta: float\n    weight: float\n\nclass LocalizationSystem:\n    def __init__(self, map_resolution=0.05, particle_count=1000):\n        self.map_resolution = map_resolution\n        self.particle_count = particle_count\n        self.particles = []\n        self.current_pose = Pose2D(0.0, 0.0, 0.0)\n        self.map = None\n        self.odom_pose = Pose2D(0.0, 0.0, 0.0)\n\n        # Motion model parameters\n        self.motion_model_params = {\n            \'alpha1\': 0.2,  # Rotation noise from rotation\n            \'alpha2\': 0.2,  # Rotation noise from translation\n            \'alpha3\': 0.2,  # Translation noise from translation\n            \'alpha4\': 0.2   # Translation noise from rotation\n        }\n\n        # Sensor model parameters\n        self.sensor_model_params = {\n            \'z_hit\': 0.8,       # Probability of hit\n            \'z_short\': 0.1,     # Probability of short reading\n            \'z_max\': 0.05,      # Probability of max reading\n            \'z_rand\': 0.05,     # Probability of random reading\n            \'sigma_hit\': 0.2,   # Standard deviation of hit\n            \'lambda_short\': 0.1 # Decay rate of short reading\n        }\n\n        self.lock = threading.Lock()\n\n    def initialize_particles(self, initial_pose: Pose2D, uncertainty: Tuple[float, float, float]):\n        """Initialize particles with given uncertainty"""\n        self.particles = []\n\n        for _ in range(self.particle_count):\n            # Add Gaussian noise to initial pose\n            x = initial_pose.x + np.random.normal(0, uncertainty[0])\n            y = initial_pose.y + np.random.normal(0, uncertainty[1])\n            theta = initial_pose.theta + np.random.normal(0, uncertainty[2])\n\n            # Normalize theta to [-\u03c0, \u03c0]\n            theta = math.atan2(math.sin(theta), math.cos(theta))\n\n            particle = Particle(x=x, y=y, theta=theta, weight=1.0/self.particle_count)\n            self.particles.append(particle)\n\n    def predict_motion(self, control: Tuple[float, float], dt: float):\n        """Predict robot motion based on control input"""\n        with self.lock:\n            for particle in self.particles:\n                # Extract control inputs\n                delta_rot1, delta_trans, delta_rot2 = self._odometry_motion_model(\n                    particle.x, particle.y, particle.theta,\n                    control[0], control[1], dt\n                )\n\n                # Add noise to motion\n                noise_rot1 = np.random.normal(0, self._get_rotation_noise(delta_rot1))\n                noise_trans = np.random.normal(0, self._get_translation_noise(delta_trans))\n                noise_rot2 = np.random.normal(0, self._get_rotation_noise(delta_rot2))\n\n                # Update particle pose\n                particle.x += (delta_trans + noise_trans) * math.cos(particle.theta + delta_rot1 + noise_rot1)\n                particle.y += (delta_trans + noise_trans) * math.sin(particle.theta + delta_rot1 + noise_rot1)\n                particle.theta += delta_rot1 + noise_rot1 + delta_rot2 + noise_rot2\n\n                # Normalize theta\n                particle.theta = math.atan2(math.sin(particle.theta), math.cos(particle.theta))\n\n    def update_weights(self, sensor_data: List[float]):\n        """Update particle weights based on sensor observations"""\n        with self.lock:\n            total_weight = 0.0\n\n            for particle in self.particles:\n                weight = self._sensor_model(particle, sensor_data)\n                particle.weight = weight\n                total_weight += weight\n\n            # Normalize weights\n            if total_weight > 0:\n                for particle in self.particles:\n                    particle.weight /= total_weight\n            else:\n                # If all weights are zero, reset to uniform distribution\n                for particle in self.particles:\n                    particle.weight = 1.0 / self.particle_count\n\n    def resample(self):\n        """Resample particles based on their weights"""\n        with self.lock:\n            # Calculate cumulative weights\n            cumulative_weights = []\n            cumsum = 0.0\n            for particle in self.particles:\n                cumsum += particle.weight\n                cumulative_weights.append(cumsum)\n\n            # Resample\n            new_particles = []\n            for _ in range(self.particle_count):\n                # Sample a random value\n                rand_val = np.random.random()\n\n                # Find particle with cumulative weight >= rand_val\n                for i, cum_weight in enumerate(cumulative_weights):\n                    if rand_val <= cum_weight:\n                        # Add particle to new set\n                        new_particle = Particle(\n                            x=self.particles[i].x,\n                            y=self.particles[i].y,\n                            theta=self.particles[i].theta,\n                            weight=1.0 / self.particle_count\n                        )\n                        new_particles.append(new_particle)\n                        break\n\n            self.particles = new_particles\n\n    def estimate_pose(self) -> Pose2D:\n        """Estimate robot pose from particles"""\n        with self.lock:\n            if not self.particles:\n                return self.current_pose\n\n            # Calculate weighted average\n            x_sum = 0.0\n            y_sum = 0.0\n            theta_sin_sum = 0.0\n            theta_cos_sum = 0.0\n\n            for particle in self.particles:\n                x_sum += particle.weight * particle.x\n                y_sum += particle.weight * particle.y\n                theta_sin_sum += particle.weight * math.sin(particle.theta)\n                theta_cos_sum += particle.weight * math.cos(particle.theta)\n\n            estimated_x = x_sum\n            estimated_y = y_sum\n            estimated_theta = math.atan2(theta_sin_sum, theta_cos_sum)\n\n            self.current_pose = Pose2D(estimated_x, estimated_y, estimated_theta)\n            return self.current_pose\n\n    def _odometry_motion_model(self, x: float, y: float, theta: float,\n                              rot1: float, trans: float, rot2: float, dt: float = 1.0) -> Tuple[float, float, float]:\n        """Odometry motion model for particle prediction"""\n        # This is a simplified version - in practice, would use actual odometry\n        return rot1, trans, rot2\n\n    def _get_rotation_noise(self, rotation: float) -> float:\n        """Get rotation noise based on motion model parameters"""\n        return math.sqrt(\n            self.motion_model_params[\'alpha1\'] * rotation**2 +\n            self.motion_model_params[\'alpha2\'] * rotation**2\n        )\n\n    def _get_translation_noise(self, translation: float) -> float:\n        """Get translation noise based on motion model parameters"""\n        return math.sqrt(\n            self.motion_model_params[\'alpha3\'] * translation**2 +\n            self.motion_model_params[\'alpha4\'] * translation**2\n        )\n\n    def _sensor_model(self, particle: Particle, sensor_data: List[float]) -> float:\n        """Calculate likelihood of sensor readings given particle pose"""\n        # Simplified sensor model\n        # In practice, this would use ray casting to the map\n        total_likelihood = 1.0\n\n        for i, sensor_reading in enumerate(sensor_data):\n            if i < len(sensor_reading):  # Simplified for example\n                # Calculate expected reading at particle\'s pose\n                expected_reading = self._expected_sensor_reading(particle, i)\n\n                # Calculate likelihood\n                likelihood = self._gaussian_likelihood(sensor_reading, expected_reading, 0.1)\n                total_likelihood *= likelihood\n\n        return total_likelihood\n\n    def _expected_sensor_reading(self, particle: Particle, beam_index: int) -> float:\n        """Calculate expected sensor reading for a particle"""\n        # Simplified - in practice, this would cast rays to the map\n        return 1.0  # Default reading\n\n    def _gaussian_likelihood(self, measurement: float, expected: float, sigma: float) -> float:\n        """Calculate Gaussian likelihood"""\n        diff = measurement - expected\n        return math.exp(-0.5 * (diff / sigma)**2)\n\n    def set_map(self, occupancy_map: np.ndarray, origin: Tuple[float, float]):\n        """Set the occupancy map for localization"""\n        self.map = occupancy_map\n        self.map_origin = origin\n'})}),"\n",(0,o.jsx)(e.h2,{id:"path-planning-system",children:"Path Planning System"}),"\n",(0,o.jsx)(e.h3,{id:"global-and-local-path-planning",children:"Global and Local Path Planning"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import heapq\nfrom scipy.spatial import KDTree\nimport numpy as np\nfrom typing import List, Tuple, Optional\n\nclass PathPlanner:\n    def __init__(self, map_resolution=0.05, inflation_radius=0.5):\n        self.map_resolution = map_resolution\n        self.inflation_radius = inflation_radius\n        self.occupancy_map = None\n        self.map_origin = (0, 0)\n        self.kd_tree = None\n\n    def set_map(self, occupancy_map: np.ndarray, origin: Tuple[float, float]):\n        """Set the occupancy map for path planning"""\n        self.occupancy_map = occupancy_map\n        self.map_origin = origin\n\n    def plan_global_path(self, start: Pose2D, goal: Pose2D) -> Optional[List[Pose2D]]:\n        """Plan global path using A* algorithm"""\n        if self.occupancy_map is None:\n            return None\n\n        # Convert world coordinates to grid coordinates\n        start_grid = self._world_to_grid((start.x, start.y))\n        goal_grid = self._world_to_grid((goal.x, goal.y))\n\n        # Check if start and goal are valid\n        if not self._is_valid_cell(start_grid) or not self._is_valid_cell(goal_grid):\n            return None\n\n        # Run A* path planning\n        path_grid = self._a_star(start_grid, goal_grid)\n\n        if path_grid is None:\n            return None\n\n        # Convert grid path back to world coordinates\n        path_world = [Pose2D(x, y, 0.0) for x, y in [self._grid_to_world(cell) for cell in path_grid]]\n\n        return path_world\n\n    def _world_to_grid(self, world_coord: Tuple[float, float]) -> Tuple[int, int]:\n        """Convert world coordinates to grid coordinates"""\n        x, y = world_coord\n        grid_x = int((x - self.map_origin[0]) / self.map_resolution)\n        grid_y = int((y - self.map_origin[1]) / self.map_resolution)\n        return (grid_x, grid_y)\n\n    def _grid_to_world(self, grid_coord: Tuple[int, int]) -> Tuple[float, float]:\n        """Convert grid coordinates to world coordinates"""\n        grid_x, grid_y = grid_coord\n        world_x = self.map_origin[0] + grid_x * self.map_resolution\n        world_y = self.map_origin[1] + grid_y * self.map_resolution\n        return (world_x, world_y)\n\n    def _is_valid_cell(self, cell: Tuple[int, int]) -> bool:\n        """Check if grid cell is valid (within bounds and not occupied)"""\n        x, y = cell\n\n        # Check bounds\n        if x < 0 or x >= self.occupancy_map.shape[1] or y < 0 or y >= self.occupancy_map.shape[0]:\n            return False\n\n        # Check occupancy (assuming 100 = occupied, 0 = free)\n        return self.occupancy_map[y, x] < 50  # Threshold for "free"\n\n    def _a_star(self, start: Tuple[int, int], goal: Tuple[int, int]) -> Optional[List[Tuple[int, int]]]:\n        """A* path planning algorithm"""\n        # Heuristic function (Euclidean distance)\n        def heuristic(a, b):\n            return np.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n\n        # Priority queue: (cost, position)\n        open_set = [(0, start)]\n        came_from = {}\n        g_score = {start: 0}\n        f_score = {start: heuristic(start, goal)}\n\n        # Closed set\n        closed_set = set()\n\n        # 8-connected neighborhood\n        neighbors = [\n            (-1, -1), (-1, 0), (-1, 1),\n            (0, -1),           (0, 1),\n            (1, -1),  (1, 0),  (1, 1)\n        ]\n\n        while open_set:\n            current_cost, current = heapq.heappop(open_set)\n\n            if current == goal:\n                # Reconstruct path\n                path = []\n                while current in came_from:\n                    path.append(current)\n                    current = came_from[current]\n                path.append(start)\n                return path[::-1]  # Reverse to get start-to-goal\n\n            closed_set.add(current)\n\n            for dx, dy in neighbors:\n                neighbor = (current[0] + dx, current[1] + dy)\n\n                if neighbor in closed_set:\n                    continue\n\n                if not self._is_valid_cell(neighbor):\n                    continue\n\n                # Calculate tentative g_score\n                movement_cost = np.sqrt(dx**2 + dy**2)  # Diagonal movement cost\n                tentative_g = g_score[current] + movement_cost\n\n                if neighbor not in g_score or tentative_g < g_score[neighbor]:\n                    # This path to neighbor is better\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g\n                    f_score[neighbor] = tentative_g + heuristic(neighbor, goal)\n\n                    if neighbor not in [item[1] for item in open_set]:\n                        heapq.heappush(open_set, (f_score[neighbor], neighbor))\n\n        # No path found\n        return None\n\n    def smooth_path(self, path: List[Pose2D]) -> List[Pose2D]:\n        """Smooth the path using path optimization techniques"""\n        if len(path) < 3:\n            return path\n\n        smoothed_path = [path[0]]  # Start with first point\n\n        i = 0\n        while i < len(path) - 1:\n            # Try to find the furthest point that can be connected directly\n            j = len(path) - 1\n\n            while j > i + 1:\n                # Check if direct path from path[i] to path[j] is collision-free\n                if self._is_line_clear((path[i].x, path[i].y), (path[j].x, path[j].y)):\n                    smoothed_path.append(path[j])\n                    i = j\n                    break\n                else:\n                    j -= 1\n\n            if j == i + 1:  # No shortcut found, add next point\n                smoothed_path.append(path[i + 1])\n                i += 1\n\n        return smoothed_path\n\n    def _is_line_clear(self, start: Tuple[float, float], end: Tuple[float, float]) -> bool:\n        """Check if line between two points is clear of obstacles"""\n        # Simple Bresenham\'s line algorithm for collision checking\n        x0, y0 = self._world_to_grid(start)\n        x1, y1 = self._world_to_grid(end)\n\n        dx = abs(x1 - x0)\n        dy = abs(y1 - y0)\n        sx = 1 if x0 < x1 else -1\n        sy = 1 if y0 < y1 else -1\n        err = dx - dy\n\n        x, y = x0, y0\n\n        while True:\n            if not self._is_valid_cell((x, y)):\n                return False\n\n            if x == x1 and y == y1:\n                break\n\n            e2 = 2 * err\n            if e2 > -dy:\n                err -= dy\n                x += sx\n            if e2 < dx:\n                err += dx\n                y += sy\n\n        return True\n'})}),"\n",(0,o.jsx)(e.h2,{id:"local-path-planning-and-obstacle-avoidance",children:"Local Path Planning and Obstacle Avoidance"}),"\n",(0,o.jsx)(e.h3,{id:"dynamic-window-approach-dwa",children:"Dynamic Window Approach (DWA)"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class LocalPlanner:\n    def __init__(self, robot_radius=0.3, max_vel_x=0.5, min_vel_x=0.0,\n                 max_vel_theta=1.0, min_vel_theta=-1.0, max_acc_x=2.5, max_acc_theta=3.2,\n                 dt=0.1, predict_time=1.5, heading_weight=0.8, velocity_weight=1.0,\n                 obstacle_weight=1.5):\n        self.robot_radius = robot_radius\n        self.max_vel_x = max_vel_x\n        self.min_vel_x = min_vel_x\n        self.max_vel_theta = max_vel_theta\n        self.min_vel_theta = min_vel_theta\n        self.max_acc_x = max_acc_x\n        self.max_acc_theta = max_acc_theta\n        self.dt = dt\n        self.predict_time = predict_time\n        self.heading_weight = heading_weight\n        self.velocity_weight = velocity_weight\n        self.obstacle_weight = obstacle_weight\n\n    def plan_local_path(self, current_pose: Pose2D, current_vel: Tuple[float, float],\n                       goal: Pose2D, obstacles: List[Tuple[float, float]]) -> Tuple[float, float]:\n        """Plan local path using Dynamic Window Approach"""\n        # Calculate velocity window\n        vs = self._calc_dynamic_window(current_vel)\n\n        # Initialize best trajectory and score\n        best_traj = None\n        best_score = float(\'-inf\')\n\n        # Evaluate all possible velocities in the window\n        for vel_x in np.arange(vs[0], vs[1], 0.1):\n            for vel_theta in np.arange(vs[2], vs[3], 0.05):\n                # Simulate trajectory\n                traj = self._predict_trajectory(current_pose, (vel_x, vel_theta))\n\n                # Calculate scores\n                heading_score = self._heading_score(traj, goal)\n                velocity_score = self._velocity_score((vel_x, vel_theta))\n                obstacle_score = self._obstacle_score(traj, obstacles)\n\n                # Calculate total score\n                total_score = (\n                    self.heading_weight * heading_score +\n                    self.velocity_weight * velocity_score -\n                    self.obstacle_weight * obstacle_score\n                )\n\n                if total_score > best_score:\n                    best_score = total_score\n                    best_traj = (vel_x, vel_theta)\n\n        if best_traj is None:\n            # Emergency stop if no valid trajectory found\n            return (0.0, 0.0)\n\n        return best_traj\n\n    def _calc_dynamic_window(self, current_vel: Tuple[float, float]) -> Tuple[float, float, float, float]:\n        """Calculate dynamic window based on current velocity and constraints"""\n        # Current velocity\n        vel_x, vel_theta = current_vel\n\n        # Calculate dynamic window\n        min_vel_x = max(self.min_vel_x, vel_x - self.max_acc_x * self.dt)\n        max_vel_x = min(self.max_vel_x, vel_x + self.max_acc_x * self.dt)\n        min_vel_theta = max(self.min_vel_theta, vel_theta - self.max_acc_theta * self.dt)\n        max_vel_theta = min(self.max_vel_theta, vel_theta + self.max_acc_theta * self.dt)\n\n        return (min_vel_x, max_vel_x, min_vel_theta, max_vel_theta)\n\n    def _predict_trajectory(self, start_pose: Pose2D, velocity: Tuple[float, float]) -> List[Pose2D]:\n        """Predict trajectory based on constant velocity model"""\n        traj = []\n        pose = Pose2D(start_pose.x, start_pose.y, start_pose.theta)\n        vel_x, vel_theta = velocity\n\n        time_steps = int(self.predict_time / self.dt)\n\n        for _ in range(time_steps):\n            # Update pose using motion model\n            pose.x += vel_x * math.cos(pose.theta) * self.dt\n            pose.y += vel_x * math.sin(pose.theta) * self.dt\n            pose.theta += vel_theta * self.dt\n\n            # Normalize theta\n            pose.theta = math.atan2(math.sin(pose.theta), math.cos(pose.theta))\n\n            traj.append(Pose2D(pose.x, pose.y, pose.theta))\n\n        return traj\n\n    def _heading_score(self, trajectory: List[Pose2D], goal: Pose2D) -> float:\n        """Calculate score based on heading towards goal"""\n        if not trajectory:\n            return 0.0\n\n        # Calculate angle between robot orientation and goal\n        final_pose = trajectory[-1]\n        angle_to_goal = math.atan2(goal.y - final_pose.y, goal.x - final_pose.x)\n        heading_error = abs(angle_to_goal - final_pose.theta)\n\n        # Normalize to [0, \u03c0] and invert (higher score = better heading)\n        heading_error = min(heading_error, 2 * math.pi - heading_error)\n        return math.pi - heading_error\n\n    def _velocity_score(self, velocity: Tuple[float, float]) -> float:\n        """Calculate score based on forward velocity"""\n        vel_x, _ = velocity\n        return vel_x  # Higher forward velocity = higher score\n\n    def _obstacle_score(self, trajectory: List[Pose2D], obstacles: List[Tuple[float, float]]) -> float:\n        """Calculate score based on obstacle proximity"""\n        if not trajectory or not obstacles:\n            return 0.0\n\n        min_dist = float(\'inf\')\n\n        for pose in trajectory:\n            for obs_x, obs_y in obstacles:\n                dist = math.sqrt((pose.x - obs_x)**2 + (pose.y - obs_y)**2)\n                min_dist = min(min_dist, dist)\n\n        # Return inverse of distance (closer to obstacles = worse score)\n        if min_dist == float(\'inf\'):\n            return 0.0\n        return 1.0 / min_dist if min_dist > 0 else float(\'inf\')\n'})}),"\n",(0,o.jsx)(e.h2,{id:"navigation-integration",children:"Navigation Integration"}),"\n",(0,o.jsx)(e.h3,{id:"complete-navigation-system",children:"Complete Navigation System"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import threading\nimport time\nfrom collections import deque\n\nclass NavigationSystem:\n    def __init__(self):\n        # Initialize components\n        self.localization = LocalizationSystem()\n        self.path_planner = PathPlanner()\n        self.local_planner = LocalPlanner()\n        self.current_goal = None\n        self.current_path = []\n        self.path_index = 0\n        self.is_navigating = False\n        self.navigation_thread = None\n        self.shutdown_flag = threading.Event()\n\n        # State variables\n        self.current_pose = Pose2D(0, 0, 0)\n        self.current_velocity = (0.0, 0.0)\n        self.obstacles = []\n\n        # Navigation parameters\n        self.arrival_threshold = 0.5  # meters\n        self.replan_threshold = 1.0   # meters\n        self.control_frequency = 10.0  # Hz\n\n        # Threading\n        self.nav_lock = threading.Lock()\n        self.command_queue = deque()\n\n    def set_map(self, occupancy_map: np.ndarray, map_origin: Tuple[float, float]):\n        """Set the map for navigation"""\n        self.localization.set_map(occupancy_map, map_origin)\n        self.path_planner.set_map(occupancy_map, map_origin)\n\n    def navigate_to_goal(self, goal_pose: Pose2D):\n        """Start navigation to goal pose"""\n        with self.nav_lock:\n            if self.is_navigating:\n                self.cancel_navigation()\n\n            self.current_goal = goal_pose\n            self.current_path = []\n            self.path_index = 0\n            self.is_navigating = True\n\n            # Plan initial path\n            start_pose = self.localization.estimate_pose()\n            path = self.path_planner.plan_global_path(start_pose, goal_pose)\n\n            if path:\n                self.current_path = self.path_planner.smooth_path(path)\n                self.path_index = 0\n            else:\n                print("Failed to plan path to goal")\n                self.is_navigating = False\n                return False\n\n        # Start navigation thread\n        self.navigation_thread = threading.Thread(target=self._navigation_worker)\n        self.navigation_thread.daemon = True\n        self.navigation_thread.start()\n\n        return True\n\n    def cancel_navigation(self):\n        """Cancel current navigation"""\n        with self.nav_lock:\n            self.is_navigating = False\n            self.current_goal = None\n            self.current_path = []\n\n    def _navigation_worker(self):\n        """Navigation worker thread"""\n        rate = 1.0 / self.control_frequency  # seconds per control cycle\n\n        while self.is_navigating and not self.shutdown_flag.is_set():\n            start_time = time.time()\n\n            try:\n                # Update current pose\n                self.current_pose = self.localization.estimate_pose()\n\n                # Check if goal reached\n                if self._is_goal_reached():\n                    print("Navigation goal reached!")\n                    self._stop_navigation()\n                    break\n\n                # Check if replanning is needed\n                if self._needs_replanning():\n                    self._replan_path()\n\n                # Execute local planning\n                if self.current_path:\n                    cmd_vel = self._execute_local_planning()\n\n                    # Send velocity command to robot\n                    self._send_velocity_command(cmd_vel)\n\n            except Exception as e:\n                print(f"Navigation error: {e}")\n                self._stop_navigation()\n                break\n\n            # Control rate\n            elapsed = time.time() - start_time\n            sleep_time = max(0, rate - elapsed)\n            time.sleep(sleep_time)\n\n    def _is_goal_reached(self) -> bool:\n        """Check if robot has reached goal"""\n        if not self.current_goal:\n            return True\n\n        dist_to_goal = math.sqrt(\n            (self.current_pose.x - self.current_goal.x)**2 +\n            (self.current_pose.y - self.current_goal.y)**2\n        )\n\n        return dist_to_goal <= self.arrival_threshold\n\n    def _needs_replanning(self) -> bool:\n        """Check if path replanning is needed"""\n        if not self.current_path or self.path_index >= len(self.current_path):\n            return True\n\n        # Check if current path is too far from robot\n        next_waypoint = self.current_path[min(self.path_index, len(self.current_path)-1)]\n        dist_to_waypoint = math.sqrt(\n            (self.current_pose.x - next_waypoint.x)**2 +\n            (self.current_pose.y - next_waypoint.y)**2\n        )\n\n        return dist_to_waypoint > self.replan_threshold\n\n    def _replan_path(self):\n        """Replan path to goal"""\n        if not self.current_goal:\n            return\n\n        start_pose = self.current_pose\n        path = self.path_planner.plan_global_path(start_pose, self.current_goal)\n\n        if path:\n            self.current_path = self.path_planner.smooth_path(path)\n            self.path_index = 0\n        else:\n            print("Failed to replan path to goal")\n\n    def _execute_local_planning(self) -> Tuple[float, float]:\n        """Execute local planning to follow path"""\n        if not self.current_path or self.path_index >= len(self.current_path):\n            return (0.0, 0.0)\n\n        # Determine next waypoint to follow\n        target_waypoint = self.current_path[min(self.path_index, len(self.current_path)-1)]\n\n        # Update path index if close to current waypoint\n        dist_to_waypoint = math.sqrt(\n            (self.current_pose.x - target_waypoint.x)**2 +\n            (self.current_pose.y - target_waypoint.y)**2\n        )\n\n        if dist_to_waypoint < 0.3:  # Waypoint reached threshold\n            self.path_index += 1\n\n        # Plan local trajectory to waypoint\n        cmd_vel = self.local_planner.plan_local_path(\n            self.current_pose,\n            self.current_velocity,\n            target_waypoint,\n            self.obstacles\n        )\n\n        return cmd_vel\n\n    def _send_velocity_command(self, cmd_vel: Tuple[float, float]):\n        """Send velocity command to robot (ROS 2 interface would go here)"""\n        # This is where ROS 2 publisher would send Twist message\n        # For now, just print for simulation\n        print(f"Sending velocity command: linear={cmd_vel[0]:.2f}, angular={cmd_vel[1]:.2f}")\n\n    def _stop_navigation(self):\n        """Stop navigation and send zero velocity"""\n        with self.nav_lock:\n            self.is_navigating = False\n            self.current_goal = None\n            self.current_path = []\n\n        # Send stop command\n        self._send_velocity_command((0.0, 0.0))\n\n    def update_sensor_data(self, laser_scan: List[float], imu_data: dict,\n                          odometry_data: dict, camera_data: dict = None):\n        """Update sensor data for navigation"""\n        # Process laser scan for obstacle detection\n        if laser_scan:\n            self.obstacles = self._process_laser_scan(laser_scan)\n\n        # Update localization with sensor data\n        self.localization.update_weights(laser_scan if laser_scan else [])\n\n        # Update odometry\n        if odometry_data:\n            self.current_velocity = (\n                odometry_data.get(\'linear_vel\', 0.0),\n                odometry_data.get(\'angular_vel\', 0.0)\n            )\n\n    def _process_laser_scan(self, laser_scan: List[float]) -> List[Tuple[float, float]]:\n        """Process laser scan to extract obstacles"""\n        obstacles = []\n\n        if not laser_scan:\n            return obstacles\n\n        # Convert laser scan to Cartesian coordinates\n        angle_increment = 2 * math.pi / len(laser_scan)\n\n        for i, range_val in enumerate(laser_scan):\n            if not (np.isnan(range_val) or np.isinf(range_val)) and 0.1 < range_val < 10.0:\n                angle = i * angle_increment\n                x = range_val * math.cos(angle)\n                y = range_val * math.sin(angle)\n\n                # Transform to global coordinates using current pose\n                global_x = self.current_pose.x + x * math.cos(self.current_pose.theta) - y * math.sin(self.current_pose.theta)\n                global_y = self.current_pose.y + x * math.sin(self.current_pose.theta) + y * math.cos(self.current_pose.theta)\n\n                obstacles.append((global_x, global_y))\n\n        return obstacles\n\n    def get_navigation_status(self) -> dict:\n        """Get current navigation status"""\n        return {\n            \'is_navigating\': self.is_navigating,\n            \'current_pose\': self.current_pose,\n            \'current_goal\': self.current_goal,\n            \'path_remaining\': len(self.current_path) - self.path_index if self.current_path else 0,\n            \'distance_to_goal\': self._get_distance_to_goal()\n        }\n\n    def _get_distance_to_goal(self) -> float:\n        """Get distance to goal"""\n        if not self.current_goal:\n            return float(\'inf\')\n\n        return math.sqrt(\n            (self.current_pose.x - self.current_goal.x)**2 +\n            (self.current_pose.y - self.current_goal.y)**2\n        )\n\n    def shutdown(self):\n        """Shutdown navigation system"""\n        self.shutdown_flag.set()\n        self.cancel_navigation()\n        if self.navigation_thread:\n            self.navigation_thread.join(timeout=2.0)\n'})}),"\n",(0,o.jsx)(e.h2,{id:"integration-with-voice-command-system",children:"Integration with Voice Command System"}),"\n",(0,o.jsx)(e.h3,{id:"navigation-command-handler",children:"Navigation Command Handler"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"class NavigationCommandHandler:\n    \"\"\"Handles navigation commands from voice command system\"\"\"\n\n    def __init__(self, navigation_system: NavigationSystem):\n        self.nav_system = navigation_system\n        self.location_database = self._initialize_location_database()\n        self.default_locations = {\n            'kitchen': Pose2D(5.0, 3.0, 0.0),\n            'bedroom': Pose2D(-2.0, 4.0, 0.0),\n            'living room': Pose2D(0.0, 0.0, 0.0),\n            'office': Pose2D(-1.0, -3.0, 0.0),\n            'bathroom': Pose2D(3.0, -2.0, 0.0)\n        }\n\n    def handle_navigation_command(self, entities: dict) -> dict:\n        \"\"\"Handle navigation command with entities\"\"\"\n        destination = entities.get('location', '').lower()\n\n        # Look up destination in database\n        target_pose = self._lookup_destination(destination)\n\n        if target_pose is None:\n            return {\n                'success': False,\n                'message': f\"Unknown destination: {destination}\",\n                'action': 'request_clarification',\n                'available_destinations': list(self.default_locations.keys())\n            }\n\n        # Attempt to navigate\n        success = self.nav_system.navigate_to_goal(target_pose)\n\n        if success:\n            return {\n                'success': True,\n                'message': f\"Navigating to {destination}\",\n                'action': 'navigation_started',\n                'destination': destination,\n                'target_pose': (target_pose.x, target_pose.y)\n            }\n        else:\n            return {\n                'success': False,\n                'message': f\"Could not navigate to {destination}\",\n                'action': 'navigation_failed',\n                'destination': destination\n            }\n\n    def _lookup_destination(self, location_name: str) -> Optional[Pose2D]:\n        \"\"\"Look up destination in location database\"\"\"\n        # Try exact match first\n        if location_name in self.default_locations:\n            return self.default_locations[location_name]\n\n        # Try fuzzy matching\n        for known_location in self.default_locations:\n            if location_name in known_location or known_location in location_name:\n                return self.default_locations[known_location]\n\n        # If no match found, return None\n        return None\n\n    def _initialize_location_database(self) -> dict:\n        \"\"\"Initialize location database with learned locations\"\"\"\n        # In a real system, this would load from persistent storage\n        return self.default_locations\n\n    def add_location(self, name: str, pose: Pose2D):\n        \"\"\"Add a new location to the database\"\"\"\n        self.default_locations[name] = pose\n\n    def get_known_locations(self) -> List[str]:\n        \"\"\"Get list of known locations\"\"\"\n        return list(self.default_locations.keys())\n"})}),"\n",(0,o.jsx)(e.h2,{id:"safety-and-recovery",children:"Safety and Recovery"}),"\n",(0,o.jsx)(e.h3,{id:"navigation-safety-systems",children:"Navigation Safety Systems"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'class NavigationSafetyManager:\n    """Manages safety aspects of navigation"""\n\n    def __init__(self, navigation_system: NavigationSystem):\n        self.nav_system = navigation_system\n        self.emergency_stop_active = False\n        self.safety_zones = []\n        self.collision_threshold = 0.5  # meters\n        self.emergency_stop_distance = 0.3  # meters\n        self.recovery_behaviors = {\n            \'stuck\': self._recover_from_stuck,\n            \'collision\': self._recover_from_collision,\n            \'lost\': self._recover_from_lost\n        }\n\n    def check_safety_conditions(self, obstacles: List[Tuple[float, float]]) -> dict:\n        """Check safety conditions and return any violations"""\n        safety_report = {\n            \'is_safe\': True,\n            \'violations\': [],\n            \'actions\': []\n        }\n\n        # Check for emergency stop conditions\n        if self._is_emergency_stop_needed(obstacles):\n            safety_report[\'is_safe\'] = False\n            safety_report[\'violations\'].append(\'OBSTACLE_TOO_CLOSE\')\n            safety_report[\'actions\'].append(\'EMERGENCY_STOP\')\n\n        # Check for safety zone violations\n        for zone in self.safety_zones:\n            if self._is_in_safety_zone(zone):\n                safety_report[\'is_safe\'] = False\n                safety_report[\'violations\'].append(f\'SAFETY_ZONE_VIOLATION: {zone["name"]}\')\n                safety_report[\'actions\'].append(\'AVOID_ZONE\')\n\n        # Check for human presence\n        if self._is_human_too_close(obstacles):\n            safety_report[\'is_safe\'] = False\n            safety_report[\'violations\'].append(\'HUMAN_TOO_CLOSE\')\n            safety_report[\'actions\'].append(\'SLOW_DOWN\')\n\n        return safety_report\n\n    def _is_emergency_stop_needed(self, obstacles: List[Tuple[float, float]]) -> bool:\n        """Check if emergency stop is needed due to close obstacles"""\n        if not obstacles:\n            return False\n\n        # Find closest obstacle\n        closest_dist = float(\'inf\')\n        for obs_x, obs_y in obstacles:\n            dist = math.sqrt(obs_x**2 + obs_y**2)  # Relative to robot\n            closest_dist = min(closest_dist, dist)\n\n        return closest_dist < self.emergency_stop_distance\n\n    def _is_human_too_close(self, obstacles: List[Tuple[float, float]]) -> bool:\n        """Check if humans are too close (simplified human detection)"""\n        # In a real system, this would use human detection algorithms\n        # For now, assume obstacles within certain range might be humans\n        if not obstacles:\n            return False\n\n        for obs_x, obs_y in obstacles:\n            dist = math.sqrt(obs_x**2 + obs_y**2)\n            if dist < 1.0:  # Within 1 meter\n                return True\n\n        return False\n\n    def _is_in_safety_zone(self, zone: dict) -> bool:\n        """Check if robot is in a safety zone"""\n        # Simplified implementation\n        current_pose = self.nav_system.current_pose\n        zone_center = zone[\'center\']\n        zone_radius = zone[\'radius\']\n\n        dist = math.sqrt(\n            (current_pose.x - zone_center[0])**2 +\n            (current_pose.y - zone_center[1])**2\n        )\n\n        return dist <= zone_radius\n\n    def activate_emergency_stop(self):\n        """Activate emergency stop"""\n        self.emergency_stop_active = True\n        self.nav_system._send_velocity_command((0.0, 0.0))\n\n    def deactivate_emergency_stop(self):\n        """Deactivate emergency stop"""\n        self.emergency_stop_active = False\n\n    def add_safety_zone(self, name: str, center: Tuple[float, float], radius: float,\n                       zone_type: str = \'restricted\'):\n        """Add a safety zone"""\n        zone = {\n            \'name\': name,\n            \'center\': center,\n            \'radius\': radius,\n            \'type\': zone_type\n        }\n        self.safety_zones.append(zone)\n\n    def _recover_from_stuck(self):\n        """Recovery behavior for stuck robot"""\n        print("Attempting recovery from stuck condition...")\n        # Implement backing up and turning\n        self.nav_system._send_velocity_command((-0.2, 0.5))  # Back up and turn\n        time.sleep(2.0)\n        self.nav_system._send_velocity_command((0.0, 0.0))   # Stop\n\n    def _recover_from_collision(self):\n        """Recovery behavior for collision"""\n        print("Collision detected, attempting recovery...")\n        # Implement collision recovery\n        self.nav_system._send_velocity_command((-0.3, 0.0))  # Back up\n        time.sleep(1.5)\n        self.nav_system._send_velocity_command((0.0, 0.0))   # Stop\n\n    def _recover_from_lost(self):\n        """Recovery behavior for lost localization"""\n        print("Localization lost, attempting recovery...")\n        # Implement relocalization strategies\n        # For now, just stop and request assistance\n        self.nav_system._send_velocity_command((0.0, 0.0))\n'})}),"\n",(0,o.jsx)(e.p,{children:"The navigation system integration provides comprehensive capabilities for autonomous humanoid robot navigation, including localization, path planning, obstacle avoidance, and safety management. This system integrates seamlessly with the voice command processing and planning systems to enable natural language navigation commands."})]})}function d(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(_,{...n})}):_(n)}},8453(n,e,t){t.d(e,{R:()=>s,x:()=>l});var a=t(6540);const o={},i=a.createContext(o);function s(n){const e=a.useContext(i);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),a.createElement(i.Provider,{value:e},n.children)}}}]);